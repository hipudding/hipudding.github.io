<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="https://dogecoin.com/assets/images/doge.svg">
  <link rel="icon" type="image/png" sizes="32x32" href="https://dogecoin.com/assets/images/doge.svg">
  <link rel="icon" type="image/png" sizes="16x16" href="https://dogecoin.com/assets/images/doge.svg">
  <link rel="mask-icon" href="https://dogecoin.com/assets/images/doge.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>



<link rel="canonical" href="http://example.com/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>hipudding's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">hipudding's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">hipudding</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/hipudding" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hipudding" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:huafengchun@gmail.com" title="E-Mail → mailto:huafengchun@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/01/23/Ray%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8-%E7%BC%96%E8%AF%91%E9%83%A8%E7%BD%B2%E5%92%8C%E4%BB%BB%E5%8A%A1%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="hipudding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hipudding's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | hipudding's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/23/Ray%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8-%E7%BC%96%E8%AF%91%E9%83%A8%E7%BD%B2%E5%92%8C%E4%BB%BB%E5%8A%A1%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/" class="post-title-link" itemprop="url">Ray技术入门-编译部署和任务生命周期</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-01-23 11:39:15 / 修改时间：11:43:24" itemprop="dateCreated datePublished" datetime="2025-01-23T11:39:15+08:00">2025-01-23</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="背景知识">背景知识</h2>
<p>Ray是一个使用Bazel构建的，基于gRPC上层打造的开源分布式计算框架，旨在简化分布式应用的开发和运行。它支持无缝地将
Python 代码扩展到多核、多节点环境，适合构建高性能的分布式系统。Ray
提供灵活的任务调度和状态管理，支持多种编程模型，包括任务并行和 actor
模式，并通过自动化的资源管理和容错机制简化复杂分布式工作的部署。它还拥有丰富的生态系统，包含机器学习库（如
Ray Tune、Ray Serve 和
RLlib），适用于模型训练、超参数调优、在线服务等场景，是云原生应用和大规模计算的理想选择。</p>
<p><strong><a
target="_blank" rel="noopener" href="https://github.com/ray-project/ray">社区</a></strong>，<strong><a
target="_blank" rel="noopener" href="https://www.ray.io/">主页</a></strong></p>
<h3 id="bazel">Bazel</h3>
<p>Bazel是一种高效、可扩展的构建工具，最初由Google开发，专为管理大型代码库和复杂项目而设计。它支持多语言和多平台构建，包括C++,
Java, Python,
Go等，并能够跨操作系统（如Linux、macOS和Windows）执行构建任务。Bazel通过声明式的构建规则（BUILD文件）和依赖管理，实现了高性能的增量构建，避免了不必要的重复编译。其特点包括分布式构建、沙盒化执行和强大的缓存机制，可以加快构建速度并提高构建的稳定性。此外，Bazel还提供高度可配置的扩展机制，方便开发者为特定需求编写自定义规则，适合从小型项目到超大规模工程的使用场景。</p>
<p><strong><a
target="_blank" rel="noopener" href="https://github.com/bazelbuild/bazel">社区</a></strong>，<strong><a
target="_blank" rel="noopener" href="https://bazel.build">主页</a></strong></p>
<h3 id="grpc">gRPC</h3>
<p>gRPC 是由 Google 开发的高性能开源 RPC 框架，基于 HTTP/2
协议，支持多语言和跨平台通信。它使用 Protocol Buffers
定义接口和序列化数据，简化了服务间的集成开发。gRPC
提供高效的请求-响应模型、流式传输、负载均衡和内置 TLS
安全特性，非常适合云原生应用、微服务架构和实时通信场景，广泛应用于分布式系统和高性能应用开发中。</p>
<p><strong><a
target="_blank" rel="noopener" href="https://github.com/grpc/grpc">社区</a></strong>，<strong><a
target="_blank" rel="noopener" href="https://grpc.io/">主页</a></strong></p>
<h3 id="cython">cython</h3>
<p>Cython 是一种优化的 Python 扩展语言，结合了 Python 的易用性和 C
的高性能，旨在提升 Python 代码的运行速度。通过将 Python 代码转译为 C 或
C++ 并进行编译，Cython 可以显著减少运行时的性能开销，同时支持调用 C/C++
库，从而实现与底层代码的高效交互。Cython 保留了大部分 Python
的语法，同时允许使用 C
类型声明进行性能优化，非常适合计算密集型任务或对性能要求较高的场景，如科学计算、机器学习和数据处理。</p>
<p><strong><a
target="_blank" rel="noopener" href="https://github.com/cython/cython">社区</a></strong>，<strong><a
target="_blank" rel="noopener" href="https://cython.org/">主页</a></strong></p>
<h2 id="角色">角色</h2>
<p>Ray集群的整体架构如下图所示</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/06_Ray架构图-20250121160411114.png"
alt="Ray架构图" />
<figcaption aria-hidden="true">Ray架构图</figcaption>
</figure>
<p>一个Ray集群包括多个Node节点，其中每个Node节点包含Actor，Worker，共享内存，本地调度器。其中Head
Node还有GCS服务，包含各类元数据存储，WebUI，全局调度等功能。</p>
<h3 id="node">Node</h3>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/v2-cf09ec3ccc183b816fa303164f4144b3_1440w.jpg"
alt="Ray Nodes" />
<figcaption aria-hidden="true">Ray Nodes</figcaption>
</figure>
<p>Node中包含一个Raylet进程，负责本地调度以及共享内存。Raylet会根据任务情况启动一个或者多个worker或者Actor。Head
node是一个特殊的Node，除了普通Node的功能之外，还有一些外的进程，包括gcs_server服务，dashboard等。并且每个Node节点还会启动monitor进程，log_monitor进程，agent进程等。</p>
<p>Raylet和gcs_server是非Python进程，其他辅助进程，包括Driver，worker以及Actor均是python进程（针对Python语言而言）。</p>
<h3 id="gcs_server">gcs_server</h3>
<p>Ray 的 GCS Server 是 Ray
框架的核心组件，负责元数据存储、任务调度、资源管理和集群状态维护。它通过存储模块（Redis
或 内存）管理节点和任务的生命周期，使用 Pub-Sub
系统进行状态广播，并通过高效的调度协调与其他组件（如 Scheduler, Worker,
Actor 或
Object）协作，确保系统的高性能、高可用性和灵活扩展性。gcs_server是一个非Python进程，二进制文件路径在
<code>ray/python/ray/core/src/ray/gcs/gcs_server</code>。</p>
<h3 id="raylet">raylet</h3>
<p>Raylet 是 Ray
集群中每个节点的核心运行时组件，负责任务执行、资源管理和数据依赖协调。它接收
GCS Server 分配的任务，管理本地资源，启动 Worker 进程执行任务，并通过
Plasma Store 处理数据存储与传输。同时，Raylet 定期向 GCS Server
汇报节点状态，协作实现任务调度、资源分配和故障恢复，是 Ray
分布式运行的关键执行单元。raylet是一个非Python进程，二进制文件路径在
<code>ray/python/ray/core/src/ray/raylet/raylet</code>。</p>
<h3 id="worker">worker</h3>
<p>Worker 是 Ray 中的核心计算单元，由 Raylet 启动，负责具体任务的执行和
Actor 的运行。它与 Plasma Store 协作进行数据存取，并通过与 Raylet
的通信完成任务调度和资源管理。Worker 支持多语言运行环境（如
Python、Java），能够高效并行处理任务，是 Ray
框架实现分布式计算的基础组件。</p>
<h3 id="actor">actor</h3>
<p>Actor 是 Ray
框架中的一种状态管理单元，允许用户在分布式系统中创建带有持久状态的计算对象。每个
Actor 由一个独立的 Worker
进程运行，支持并行调用方法并维护自身状态。Actor
可以通过远程调用接口与其他组件交互，实现任务分解和动态扩展，是 Ray
中用于构建有状态应用和分布式服务的重要抽象。</p>
<h3 id="driver">driver</h3>
<p>Driver就是用户程序（例如，用@ray.remote修饰的用户python代码），Driver负责Task的定义和提交，需要运行在Ray的Head或者Node节点上。</p>
<h2 id="编译">编译</h2>
<p>安装Ray有多种方法，包括wheel包，pip，conda，容器镜像等。这些内容可以参考<a
target="_blank" rel="noopener" href="https://docs.ray.io/en/latest/ray-overview/installation.html">社区手册</a>。这里介绍从<a
target="_blank" rel="noopener" href="https://docs.ray.io/en/latest/ray-contribute/development.html#building-ray">源码安装</a>。</p>
<h3 id="使用conda环境">使用Conda环境</h3>
<p>官方推荐conda或者venv两种虚拟环境安装ray，建议选择conda。无虚拟环境将无法编译ray，并且在实测中发现了venv的未知错误。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -c conda-forge python=3.9 -n myenv</span><br><span class="line">conda activate myenv</span><br></pre></td></tr></table></figure>
<h3 id="安装依赖">安装依赖</h3>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y build-essential curl clang pkg-config psmisc unzip</span><br></pre></td></tr></table></figure>
<p><strong>安装bazel</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ci/env/install-bazel.sh</span><br></pre></td></tr></table></figure>
<p><strong>安装npm</strong></p>
<p>用于dashboard</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash">(curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh)</span></span><br><span class="line">nvm install 14</span><br><span class="line">nvm use 14</span><br></pre></td></tr></table></figure>
<h3 id="构建">构建</h3>
<p><strong>构建dashboard</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd ray/python/ray/dashboard/client</span><br><span class="line">npm ci</span><br><span class="line">npm run build</span><br></pre></td></tr></table></figure>
<p><strong>构建ray</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd ../../..</span><br><span class="line">pip install -r requirements.txt</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果构建机器的内存小于32G，需要限制内存使用，避免oom</span></span><br><span class="line">export BAZEL_ARGS=&quot;--local_ram_resources=8&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">debug编译，保留符号表供调试</span></span><br><span class="line">export RAY_DEBUG_BUILD=debug</span><br><span class="line">pip install -e . --verbose</span><br></pre></td></tr></table></figure>
<h3 id="可选的编译环境变量">可选的编译环境变量</h3>
<ul>
<li><code>RAY_INSTALL_JAVA</code>: If set and equal to <code>1</code>,
extra build steps will be executed to build java portions of the
codebase</li>
<li><code>RAY_INSTALL_CPP</code>: If set and equal to <code>1</code>,
<code>ray-cpp</code> will be installed</li>
<li><code>RAY_DISABLE_EXTRA_CPP</code>: If set and equal to
<code>1</code>, a regular (non - <code>cpp</code>) build will not
provide some <code>cpp</code> interfaces</li>
<li><code>SKIP_BAZEL_BUILD</code>: If set and equal to <code>1</code>,
no Bazel build steps will be executed</li>
<li><code>SKIP_THIRDPARTY_INSTALL</code>: If set will skip installation
of third-party python packages</li>
<li><code>RAY_DEBUG_BUILD</code>: Can be set to <code>debug</code>,
<code>asan</code>, or <code>tsan</code>. Any other value will be
ignored</li>
<li><code>BAZEL_ARGS</code>: If set, pass a space-separated set of
arguments to Bazel. This can be useful for restricting resource usage
during builds, for example. See https://bazel.build/docs/user-manual for
more information about valid arguments.</li>
<li><code>IS_AUTOMATED_BUILD</code>: Used in CI to tweak the build for
the CI machines</li>
<li><code>SRC_DIR</code>: Can be set to the root of the source checkout,
defaults to <code>None</code> which is <code>cwd()</code></li>
<li><code>BAZEL_SH</code>: used on Windows to find a
<code>bash.exe</code>, see below</li>
<li><code>BAZEL_PATH</code>: used on Windows to find
<code>bazel.exe</code>, see below</li>
<li><code>MINGW_DIR</code>: used on Windows to find
<code>bazel.exe</code> if not found in <code>BAZEL_PATH</code></li>
</ul>
<h2 id="启动一个ray集群">启动一个Ray集群</h2>
<p>接下来使用一个简单的例子来使用Ray，这是一个使用概率计算圆周率π的程序（蒙特卡洛法）。蒙特卡洛方法在计算圆周率时设一个正方形内部相切一个圆，这时圆和正方形的面积之比是π/4。在这个正方形内部，随机产生n个点（这些点服从均匀分布），计算它们与中心点的距离是否大于圆的半径，以此判断是否落在圆的内部。统计圆内的点数，与n的比值乘以4，就是π的值。理论上，n越大，计算的π值越精确。</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/3d5d171ad6df43c2babfe981a2ee91e8.jpeg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/4f050b95b2c1439baa33a66de817e659.jpeg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 Ray</span></span><br><span class="line">ray.init()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单个任务：生成点并统计圆内点数</span></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_points_in_circle</span>(<span class="params">num_samples: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_samples):</span><br><span class="line">        x, y = random.uniform(<span class="number">0</span>, <span class="number">1</span>), random.uniform(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> x**<span class="number">2</span> + y**<span class="number">2</span> &lt;= <span class="number">1</span>:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_pi</span>(<span class="params">num_samples: <span class="built_in">int</span>, num_workers: <span class="built_in">int</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    <span class="comment"># 每个 worker 分配的样本数</span></span><br><span class="line">    samples_per_worker = num_samples // num_workers</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建并运行任务</span></span><br><span class="line">    futures = [</span><br><span class="line">        count_points_in_circle.remote(samples_per_worker) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_workers)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 收集结果</span></span><br><span class="line">    total_in_circle = <span class="built_in">sum</span>(ray.get(futures))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算圆周率</span></span><br><span class="line">    pi_estimate = <span class="number">4</span> * total_in_circle / num_samples</span><br><span class="line">    <span class="keyword">return</span> pi_estimate</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 总样本数和并行任务数</span></span><br><span class="line">    total_samples = <span class="number">100_000_000</span></span><br><span class="line">    num_workers = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算 π</span></span><br><span class="line">    pi = calculate_pi(total_samples, num_workers)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Estimated π: <span class="subst">&#123;pi&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 关闭 Ray</span></span><br><span class="line">    ray.shutdown()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="临时启动">临时启动</h3>
<p>如果不启动Ray集群，直接执行该Python程序，那会在当前节点上默认拉起一个ray集群供计算。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python pi.py</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2025-01-21 09:35:24,180 INFO worker.py:1832 -- Started a <span class="built_in">local</span> Ray instance. View the dashboard at 127.0.0.1:8265</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Estimated π: 3.12</span></span><br></pre></td></tr></table></figure>
<h3 id="启动集群">启动集群</h3>
<p><strong>启动Head节点</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">ray start --head</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Local node IP: 192.168.64.8</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#--------------------</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Ray runtime started.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">--------------------</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#Next steps</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> To add another node to this Ray cluster, run</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   ray start --address=<span class="string">&#x27;192.168.64.8:6379&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#  To connect to this Ray cluster:</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   import ray</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   ray.init()</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#  To submit a Ray job using the Ray Jobs CLI:</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   RAY_ADDRESS=<span class="string">&#x27;http://127.0.0.1:8265&#x27;</span> ray job submit --working-dir . -- python my_script.py</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#  See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> <span class="keyword">for</span> more information on submitting Ray <span class="built_in">jobs</span> to the Ray cluster.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#  To terminate the Ray runtime, run</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   ray stop</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#  To view the status of the cluster, use</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   ray status</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#  To monitor and debug Ray, view the dashboard at</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   127.0.0.1:8265</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#  If connection to the dashboard fails, check your firewall settings and network configuration.</span></span></span><br></pre></td></tr></table></figure>
<p>可以在<code>http://127.0.0.1:8265</code>查看Ray控制台。</p>
<p><strong>启动Node节点</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ray start --address=&#x27;192.168.64.8:6379&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Local node IP: 192.168.64.9</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[2025-01-21 10:49:34,903 W 1882 1882] global_state_accessor.cc:463: Retrying to get node with node ID ba8aafea9f23f6f29ff6cd174e31aaac37cddb0e832c4e3170ddcf63</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#--------------------</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Ray runtime started.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">--------------------</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#To terminate the Ray runtime, run</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> ray stop</span></span><br></pre></td></tr></table></figure>
<p><strong>集群状态</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">======== Autoscaler status: 2025-01-21 10:54:25.170247 ========</span><br><span class="line">Node status</span><br><span class="line">---------------------------------------------------------------</span><br><span class="line">Active:</span><br><span class="line"> 1 node_948847515a43d4fba13c1bdb6a5e5611c2580ecb60f60183ef033771</span><br><span class="line"> 1 node_ba8aafea9f23f6f29ff6cd174e31aaac37cddb0e832c4e3170ddcf63</span><br><span class="line">Pending:</span><br><span class="line"> (no pending nodes)</span><br><span class="line">Recent failures:</span><br><span class="line"> (no failures)</span><br><span class="line"></span><br><span class="line">Resources</span><br><span class="line">---------------------------------------------------------------</span><br><span class="line">Usage:</span><br><span class="line"> 0.0/16.0 CPU</span><br><span class="line"> 0B/8.40GiB memory</span><br><span class="line"> 0B/3.93GiB object_store_memory</span><br><span class="line"></span><br><span class="line">Demands:</span><br><span class="line"> (no resource demands)</span><br></pre></td></tr></table></figure>
<h3 id="启用监控">启用监控</h3>
<p><strong>Prometheus</strong></p>
<p>ray提供了一个命令来下载和部署普罗米修斯，ray提供了数据采集接口，可以让普罗米修斯通过这个接口来收集集群数据，注意，简易命令拉起的普罗米修斯不能用于生产环境，完整部署可参考<a
target="_blank" rel="noopener" href="https://docs.ray.io/en/latest/cluster/metrics.html#optional-manual-running-prometheus-locally">官方手册</a>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ray metrics launch-prometheus</span><br></pre></td></tr></table></figure>
<p>可以在这个地址上查看普罗米修斯状态：http://localhost:9090，可查看其采集的信息<code>ray_dashboard_api_requests_count_requests_total</code>。</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20250121190550385.png"
alt="image-20250121190550385" />
<figcaption aria-hidden="true">image-20250121190550385</figcaption>
</figure>
<p><strong>grafana</strong></p>
<p>普罗米修斯采集的数据，通过grafana的方式进行可视化显示，并且ray
dashboard中的metric页面的信息也是来自于grafana。可以通过启动新的grafana服务来完成配置。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/share/grafana</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动grafana需要创建data目录，需要sudo执行</span></span><br><span class="line">sudo ./bin/grafana-server --config /tmp/ray/session_latest/metrics/grafana/grafana.ini web</span><br></pre></td></tr></table></figure>
<p>将grafana dashboard加入到已有的grafana server可以参考<a
target="_blank" rel="noopener" href="https://docs.ray.io/en/latest/cluster/metrics.html#simplest-setting-up-grafana-with-ray-provided-configurations">官方手册</a>。</p>
<p>可以在这个地址上查看grafana的dashboard：http://localhost:3000</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20250121191218231.png"
alt="image-20250121191218231" />
<figcaption aria-hidden="true">image-20250121191218231</figcaption>
</figure>
<p><strong>Ray dashboard</strong></p>
<p>完成上述两个步骤后，Ray
dashboard中的metric即可正常显示，如果不是本机部署，你可能需要配置允许所有ip访问：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RAY_GRAFANA_HOST=http://192.168.64.8:3000 ray start --head --dashboard-host=0.0.0.0</span><br></pre></td></tr></table></figure>
<p><code>RAY_GRAFANA_HOST</code>的作用是让ray的dashboard能够访问到grafana服务；</p>
<p><code>--dashboard-host=0.0.0.0</code>允许所有ip访问。</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20250121191317452.png"
alt="image-20250121191317452" />
<figcaption aria-hidden="true">image-20250121191317452</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20250121191504505.png"
alt="image-20250121191504505" />
<figcaption aria-hidden="true">image-20250121191504505</figcaption>
</figure>
<h3 id="提交一个任务">提交一个任务</h3>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python pi.py</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2025-01-21 11:17:11,760 INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.64.8:6379...</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2025-01-21 11:17:11,775 INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at 192.168.64.8:8265</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Estimated π: 3.36</span></span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20250121191829305.png"
alt="image-20250121191829305" />
<figcaption aria-hidden="true">image-20250121191829305</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20250121191902742.png"
alt="image-20250121191902742" />
<figcaption aria-hidden="true">image-20250121191902742</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20250121191917649.png"
alt="image-20250121191917649" />
<figcaption aria-hidden="true">image-20250121191917649</figcaption>
</figure>
<h3 id="部署一个服务">部署一个服务</h3>
<p>Ray除了提供基础的分布式计算能力之外，还提供了一系列的AI
libs，其中可以在其上部署服务，Ray自动提供proxy和负载均衡能力。这里使用一个翻译的服务举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> starlette.requests <span class="keyword">import</span> Request</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"><span class="keyword">from</span> ray <span class="keyword">import</span> serve</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@serve.deployment(<span class="params">num_replicas=<span class="number">2</span>, ray_actor_options=&#123;<span class="string">&quot;num_cpus&quot;</span>: <span class="number">0.2</span>, <span class="string">&quot;num_gpus&quot;</span>: <span class="number">0</span>&#125;</span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Translator</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># Load model</span></span><br><span class="line">        self.model = pipeline(<span class="string">&quot;translation_en_to_fr&quot;</span>, model=<span class="string">&quot;t5-small&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">translate</span>(<span class="params">self, text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="comment"># Run inference</span></span><br><span class="line">        model_output = self.model(text)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Post-process output to return only the translation text</span></span><br><span class="line">        translation = model_output[<span class="number">0</span>][<span class="string">&quot;translation_text&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> translation</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, http_request: Request</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        english_text: <span class="built_in">str</span> = <span class="keyword">await</span> http_request.json()</span><br><span class="line">        <span class="keyword">return</span> self.translate(english_text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">translator_app = Translator.bind()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    ray.init()</span><br><span class="line">    serve.start(http_options=&#123;<span class="string">&quot;host&quot;</span>: <span class="string">&quot;0.0.0.0&quot;</span>&#125;)  <span class="comment"># 设置监听地址为 0.0.0.0</span></span><br><span class="line">    serve.run(translator_app)</span><br></pre></td></tr></table></figure>
<p>具体修改方法，可以参考<a
target="_blank" rel="noopener" href="https://docs.ray.io/en/latest/serve/getting_started.html">官方手册</a></p>
<p>直接运行这个python程序即可完成服务的部署：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">python translate.py</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2025-01-21 11:23:45,794 INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 192.168.64.8:6379...</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2025-01-21 11:23:45,810 INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at 192.168.64.8:8265</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">INFO 2025-01-21 11:23:46,673 serve 8302 -- Started Serve <span class="keyword">in</span> namespace <span class="string">&quot;serve&quot;</span>.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">INFO 2025-01-21 11:23:46,675 serve 8302 -- Connecting to existing Serve app <span class="keyword">in</span> namespace <span class="string">&quot;serve&quot;</span>. New http options will not be applied.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">WARNING 2025-01-21 11:23:46,675 serve 8302 -- The new client HTTP config differs from the existing one <span class="keyword">in</span> the following fields: [<span class="string">&#x27;host&#x27;</span>, <span class="string">&#x27;location&#x27;</span>]. The new HTTP config is ignored.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">(ServeController pid=6931) INFO 2025-01-21 11:23:46,687 controller 6931 -- Deploying new version of Deployment(name=<span class="string">&#x27;Translator&#x27;</span>, app=<span class="string">&#x27;default&#x27;</span>) (initial target replicas: 2).</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">(ProxyActor pid=8045) INFO 2025-01-21 11:23:46,644 proxy 192.168.64.8 -- Proxy starting on node 8e8707766c1fc9b7d838c24446c99440be5881c04ea44b6e4e83a7aa (HTTP port: 8000).</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">(ProxyActor pid=8045) INFO 2025-01-21 11:23:46,660 proxy 192.168.64.8 -- Got updated endpoints: &#123;&#125;.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">(ProxyActor pid=8045) INFO 2025-01-21 11:23:46,690 proxy 192.168.64.8 -- Got updated endpoints: &#123;Deployment(name=<span class="string">&#x27;Translator&#x27;</span>, app=<span class="string">&#x27;default&#x27;</span>): EndpointInfo(route=<span class="string">&#x27;/&#x27;</span>, app_is_cross_language=False)&#125;.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">(ServeController pid=6931) INFO 2025-01-21 11:23:46,792 controller 6931 -- Adding 2 replicas to Deployment(name=<span class="string">&#x27;Translator&#x27;</span>, app=<span class="string">&#x27;default&#x27;</span>).</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">(ServeReplica:default:Translator pid=8044) Device <span class="built_in">set</span> to use cpu</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">INFO 2025-01-21 11:23:50,711 serve 8302 -- Application <span class="string">&#x27;default&#x27;</span> is ready at http://0.0.0.0:8000/.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">INFO 2025-01-21 11:23:50,711 serve 8302 -- Deployed app <span class="string">&#x27;default&#x27;</span> successfully.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">(ServeReplica:default:Translator pid=2371, ip=192.168.64.9) Device <span class="built_in">set</span> to use cpu</span></span><br></pre></td></tr></table></figure>
<p>在dashboard上可以看到服务的详情：</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20250121192836367.png"
alt="image-20250121192836367" />
<figcaption aria-hidden="true">image-20250121192836367</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20250121192851056.png"
alt="image-20250121192851056" />
<figcaption aria-hidden="true">image-20250121192851056</figcaption>
</figure>
<p>通过curl命令可以验证服务运行情况：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST http://127.0.0.1:8000/ -H &quot;Content-Type: application/json&quot; -d &#x27;&quot;Hello world!&quot;&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Bonjour monde!</span></span><br></pre></td></tr></table></figure>
<h2 id="调试">调试</h2>
<p>Ray是一个多进程，Python和C++混合调用的程序（以Python语言为例），调试上需要掌握一定的技巧。调试Python，Driver，以及自动拉起的gcs_server，raylet以及worker，actor的方法都不同。下面以VsCode为例。</p>
<h3 id="调试python">调试python</h3>
<p>Python调试与普通程序调试相同，直接点debug
python文件，或者配置launch.json即可。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Python: pi.py&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;debugpy&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;/pi.py&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;console&quot;</span><span class="punctuation">:</span> <span class="string">&quot;integratedTerminal&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;justMyCode&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;cwd&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="调试driver">调试Driver</h3>
<p>Driver就是用户python程序，调试Driver的Python部分参考上一节，如果调试Driver的C++部分，需要调试python进程，前提是Ray是debug编译的，否则没有符号表无法调试。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Ray C++&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cppdbg&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/hua/miniconda3/envs/myenv/bin/python3.9&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;$&#123;workspaceFolder&#125;/pi.py&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;stopAtEntry&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;cwd&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;environment&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;externalConsole&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;MIMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;setupCommands&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;为 gdb 启用整齐打印&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;-enable-pretty-printing&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;ignoreFailures&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;将反汇编风格设置为 Intel&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;-gdb-set disassembly-flavor intel&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;ignoreFailures&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="调试worker或者其他进程">调试Worker或者其他进程</h3>
<p>gcs_server，raylet，worker以及actor都是自动拉起的进程，调试的时候需要attach到这些进程上进行调试。</p>
<blockquote>
<p>注意，需要接触gdb attach的限制，永久接触方法如下：</p>
<p>sudo vi /etc/sysctl.d/10-ptrace.conf</p>
<p>kernel.yama.ptrace_scope = 0</p>
<p>sudo sysctl --system</p>
</blockquote>
<p>调试上述pi.py，在一个worker的情况下大概需要8G内存，否则会导致Ray
kill掉worker或者gdb异常退出。在调试worker过程中，为了方便，可以限制仅启动一个worker，在本地拉起的情况下，配置<code>ray.init(num_cpus=1)</code>。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Attach to worker&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cppdbg&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;attach&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;processId&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;command:pickProcess&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/hua/miniconda3/envs/myenv/bin/python3.9&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;sourceFileMap&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;/proc/self/cwd&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/hua/code/ray&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;setupCommands&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;为 gdb 启用整齐打印&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;-enable-pretty-printing&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;ignoreFailures&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;将反汇编风格设置为 Intel&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;-gdb-set disassembly-flavor intel&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;ignoreFailures&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>worker和actor是python进程，gcs_server和reylet是非python进程，二进制在
ray/python/ray/core/src/ray/下。</p>
<h2 id="grpc流程">gRPC流程</h2>
<h3 id="grpc是什么">gRPC是什么</h3>
<p>简单来说，RPC框架就是像调用本地函数一样调用远程函数。gRPC使用protobuf来定义服务和传输的对象，在客户端中，有一个存根（Stub），与服务有相同的函数签名，通过调用这个存根，即可完成一次RPC调用。</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/landing-2.svg"
alt="Concept Diagram" />
<figcaption aria-hidden="true">Concept Diagram</figcaption>
</figure>
<p>Ray是基于gRPC构建的分布式计算系统，有关gRPC的代码存放在
ray/src/ray/rpc目录下，下面，我们通过worker进程的gRPC服务来分析。</p>
<h3 id="grpc-client">gRPC client</h3>
<p>涉及到gRPC client的几个文件：<code>grpc_client.h</code>,
<code>client_call.h</code></p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/20250122145957615.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>ClientCall</code>是对RPC调用的一个封装，主要包括需要调用的stub函数指针，以及相关的状态和结果获取，当gRPC调用返回时，需要回调<code>ClientCall</code>中注册的回调函数。<code>ClientCallManager</code>是对gRPC调用发起的管理，包括结果队列，监听线程等，
<code>GrpcClient</code>保存的是gRPC的连接句柄，可以通过该对象发起一个gRPC请求。</p>
<p>对于CoreWorker来说，在此之上还有一层封装（<code>worker/core_worker_client.h</code>,
<code>worker/core_worker_client_pool.h/cc</code>），<code>CoreWorkerClient</code>，该类封装了CoreWorkerService可用的所用调用，直接调用提供的函数接口即可完成RPC调用。与之匹配的还有一个<code>CoreWorkerClientPool</code>，用于<code>CoreWorkerClient</code>的缓存。</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20250122142401278.png"
alt="image-20250122142401278" />
<figcaption aria-hidden="true">image-20250122142401278</figcaption>
</figure>
<p><code>CoreWorkerClientPool</code>维护一个map&lt;WorkerId,
CoreWorkerClient&gt;，当已经存在对应的<code>CoreWorkerClient</code>时直接取出使用。如果不存在，则调用<code>CoreWorkerClientFactoryFn</code>工厂方法创建一个gRPC的client连接。该工厂方法在<code>CoreWorker</code>的构造函数中定义，通过一个<code>rpc::Address</code>创建对应的<code>CoreWorkerClient</code>对象。</p>
<p>每个<code>CoreWorkerClient</code>对象构造过程中，会创建gRPC连接，并且通过<code>ClientCallManager</code>来发起RPC请求，并通过监听CompletionQueue来响应RPC的处理结果。</p>
<h3 id="grpc-server">gRPC server</h3>
<p>涉及到gRPC server的几个文件：<code>grpc_server.h/cc</code>,
<code>client_server.h/cc</code></p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/20250122145823773.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>GrpcServer</code>是gRPC的服务端，其中定义了初始化，关闭，注册服务，运行等操作。它会根据其中注册的Service来向gRPC服务中注册服务和对应的处理方法。<code>GrpcService</code>是一个虚拟类，其本身没有实现，需要不同的组件来继承实现，例如，CoreWorker就会用<code>CoreWorkerGrpcService</code>来实现一个Worker对应的Service。Service中需要提供一组<code>ServiceCallFactory</code>，这些Factory记录了服务，gRPC的stub，回调函数，本地异步IO组件等信息，供<code>GrpcServer</code>来注册对应的服务。<code>ServiceCall</code>即服务端服务的本身，包括一系列回调函数处理对应的事件，这个call对象会以Tag的方式放入gRPC请求中，处理时取出call对象对相应的处理。</p>
<p>对于CoreWorker来说，需要基于<code>GrpcService</code>实现<code>GrpcCoreWorkerGrpcService</code>（<code>work/core_worker_server.h</code>）。实际上的工作就是将CoreWorkerService中的服务全部注册到ServiceCallFactory中。</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20250122152145818.png"
alt="image-20250122152145818" />
<figcaption aria-hidden="true">image-20250122152145818</figcaption>
</figure>
<p><code>CoreWorkerServiceHandler</code>是一组Handle方法的集合，包含CoreWorkerService中的所有服务的处理方法，<code>CoreWorkerGrpcService</code>中会通过一组宏来构造protobuf中的注册，响应等必要信息的对象集合（ServiceCallFactory）。</p>
<p>注册完成后，<code>GrpcServer</code>在运行之前，会将所有的事件和响应注册到队列中，这样，队列中进入事件时，就可以调用对应的处理函数进行处理。</p>
<h3 id="本地异步调用">本地异步调用</h3>
<p>Ray使用了大量的异步处理，例如gRPC框架中的请求和响应，以及本地的异步处理框架。Ray的Worker等进程中，除了gRPC的异步框架之外，还有一个<code>boost::asio::io_context</code>框架，所有gRPC的响应并不是在pull_threads中处理，而是把事件转交给本地的异步处理框架，然后在该异步处理框架中处理。并且该框架中还内置了一个EventTracker，来记录所有时间的处理信息。</p>
<p>结果的处理交给本地异步处理来运行，猜测是为了加快gRPC队列中的数据消费。</p>
<h2 id="driver提交流程">Driver提交流程</h2>
<p>以无状态任务为例，描述任务的提交流程。</p>
<h3 id="python部分">Python部分</h3>
<p><strong><span class="citation"
data-cites="ray.remote">@ray.remote</span></strong></p>
<p>被<code>@ray.remote</code>装饰的函数会被ray分布式处理。该装饰器会将函数（或者对象，后续的描述均为函数的装饰）封装成<code>RemoteFunction</code>对象。该对象保存了被装饰函数的function对象，并且提供<code>remote</code>方法。</p>
<p>当<code>remote</code>方法被调用时，会将python函数包装成<code>PythonFunctionDescriptor</code>,记录了module/function/class
name，以及分配的uuid。随后使用pickle_dump将函数序列化，交给worker处理。worker会将序列化后的函数存储到gcs服务的function
table中，并记录该函数的uuid，以便于通过函数描述找到函数体。</p>
<p>以上工作完成后，remote方法会调用worker的submit_task方法提交任务，该任务即可通过gRPC发送到集群中处理。submit_task返回一个object_ref。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">invocation (/home/hua/code/ray/python/ray/remote_function.py:485)</span><br><span class="line">_remote (/home/hua/code/ray/python/ray/remote_function.py:504)</span><br><span class="line">_invocation_remote_span (/home/hua/code/ray/python/ray/util/tracing/tracing_helper.py:310)</span><br><span class="line">auto_init_wrapper (/home/hua/code/ray/python/ray/_private/auto_init_hook.py:21)</span><br><span class="line">_remote_proxy (/home/hua/code/ray/python/ray/remote_function.py:156)</span><br><span class="line">&lt;listcomp&gt; (/home/hua/code/ray/pi.py:23)</span><br><span class="line">calculate_pi (/home/hua/code/ray/pi.py:22)</span><br><span class="line">&lt;module&gt; (/home/hua/code/ray/pi.py:39)</span><br></pre></td></tr></table></figure>
<h3 id="driver部分">Driver部分</h3>
<p><strong>任务提交到本地</strong></p>
<p>Driver的python代码调用submit_task后，会通过cython调用到C++
extention中。对应的函数是<code>CoreWorker::SubmitTask</code>，这里会将相关的任务信息打包成<code>TaskSpec</code>，然后提交到本地异步IO中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">_raylet.so!ray::core::CoreWorker::SubmitTask() (/home/hua/code/ray/src/ray/core_worker/core_worker.cc:2467)</span><br><span class="line"></span><br><span class="line">cython ...</span><br><span class="line">Python ...</span><br></pre></td></tr></table></figure>
<p><strong>解决依赖</strong></p>
<p>从异步IO调度到该任务后(<code>NormalTaskSubmitter::SubmitTask</code>)，会先等待依赖的资源处理结束，这里使用了回调的方式异步等待依赖的任务结束。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">_raylet.so!ray::core::NormalTaskSubmitter::SubmitTask() (/home/hua/code/ray/src/ray/core_worker/transport/normal_task_submitter.cc:23)</span><br><span class="line"></span><br><span class="line">_raylet.so!operator()(const struct &#123;...&#125; * const __closure) (/home/hua/code/ray/src/ray/core_worker/core_worker.cc:2469)</span><br><span class="line"></span><br><span class="line">_raylet.so!EventTracker::RecordExecution() (/home/hua/code/ray/src/ray/common/event_stats.cc:113)</span><br><span class="line"></span><br><span class="line">_raylet.so!std::_Function_handler&lt;void(), instrumented_io_context::post() (/home/hua/code/ray/src/ray/common/asio/instrumented_io_context.cc:97)</span><br><span class="line"></span><br><span class="line">从异步IO调度</span><br></pre></td></tr></table></figure>
<p><strong>请求资源</strong></p>
<p>依赖的任务执行结束后，准备执行当前任务，但是对当前SchedulingKey来说目前没有空闲的Worker，需要先向reylet请求Worker，<code>NormalTaskSubmitter::RequestNewWorkerIfNeeded</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">_raylet.so!ray::core::NormalTaskSubmitter::RequestNewWorkerIfNeeded() (/home/hua/code/ray/src/ray/core_worker/transport/normal_task_submitter.cc:347)</span><br><span class="line"></span><br><span class="line">_raylet.so!operator()(struct &#123;...&#125; * const __closure, ray::Status status) (/home/hua/code/ray/src/ray/core_worker/transport/normal_task_submitter.cc:80)</span><br><span class="line"></span><br><span class="line">_raylet.so!ray::core::LocalDependencyResolver::ResolveDependencies() (/home/hua/code/ray/src/ray/core_worker/transport/dependency_resolver.cc:84)</span><br><span class="line"></span><br><span class="line">异步回调</span><br></pre></td></tr></table></figure>
<p><strong>任务提交到集群</strong></p>
<p>Worker资源异步请求会返回空闲Worker的Address，然后可以通过RPC将任务直接提交(<code>PushTask</code>)给这个Worker。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">_raylet.so!ray::rpc::CoreWorkerClient::PushNormalTask() (/home/hua/code/ray/src/ray/rpc/worker/core_worker_client.h:399)</span><br><span class="line"></span><br><span class="line">_raylet.so!ray::core::NormalTaskSubmitter::PushNormalTask() (/home/hua/code/ray/src/ray/core_worker/transport/normal_task_submitter.cc:561)</span><br><span class="line"></span><br><span class="line">_raylet.so!ray::core::NormalTaskSubmitter::OnWorkerIdle() (/home/hua/code/ray/src/ray/core_worker/transport/normal_task_submitter.cc:181)</span><br><span class="line"></span><br><span class="line">_raylet.so!operator()() (/home/hua/code/ray/src/ray/core_worker/transport/normal_task_submitter.cc:436)</span><br><span class="line"></span><br><span class="line">RPC回调</span><br></pre></td></tr></table></figure>
<h2 id="worker执行流程">Worker执行流程</h2>
<p><strong>调试技巧</strong></p>
<ol type="1">
<li>首先启动Driver，在<code>INVOKE_RPC_CALL</code>执行之前打断点，阻塞任务提交到集群。</li>
<li>attach到Worker进程上，并且在<code>CoreWorker::HandlePushTask</code>打断点，这里是处理RPC请求的入口。</li>
<li>让Driver继续执行，Worker就会命中断点，可以继续调试Worker。</li>
</ol>
<p><strong>gRPC将任务提交到本地</strong></p>
<p><code>GrpcServer::PollEventsFromCompletionQueue</code>会等待gRPC请求，当收到请求后，就会调用从Tag中取出ServerCall对象，该对象中保存着该请求的所有处理的必要信息。然后将该任务提交给异步IO。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">_raylet.so!ray::rpc::ServerCallImpl&lt;ray::rpc::CoreWorkerServiceHandler, ray::rpc::GetCoreWorkerStatsRequest, ray::rpc::GetCoreWorkerStatsReply, (ray::rpc::AuthType)0&gt;::HandleRequest() (/home/hua/code/ray/bazel-out/aarch64-dbg/bin/_virtual_includes/grpc_common_lib/ray/rpc/server_call.h:237)</span><br><span class="line"></span><br><span class="line">_raylet.so!ray::rpc::GrpcServer::PollEventsFromCompletionQueue() (/home/hua/code/ray/src/ray/rpc/grpc_server.cc:199)</span><br><span class="line"></span><br><span class="line">gRPC pulling thread</span><br></pre></td></tr></table></figure>
<p><strong>调用gRPC注册的Handler方法</strong></p>
<p>异步IO会回调注册的方法<code>CoreWorker::HandlePushTask</code>，配置定义<code>send_reply_callback</code>回调函数，最后将任务通过异步IO提交给<code>task_execution_service</code>（就是另外一个异步IO队列）。</p>
<p><strong>执行函数</strong></p>
<p>当执行调度到PushTask任务时，就会回调上一步配置的<code>send_reply_callback</code>回调，远程函数的执行就在这个回调中运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">_raylet.so!operator()(const struct &#123;...&#125; * const __closure, const ray::TaskSpecification &amp; task_spec, ray::rpc::SendReplyCallback send_reply_callback) (/home/hua/code/ray/src/ray/core_worker/transport/task_receiver.cc:100)</span><br><span class="line"></span><br><span class="line">_raylet.so!ray::core::InboundRequest::Accept(ray::core::InboundRequest * const this) (/home/hua/code/ray/src/ray/core_worker/transport/actor_scheduling_util.cc:36)</span><br><span class="line"></span><br><span class="line">_raylet.so!ray::core::NormalSchedulingQueue::ScheduleRequests(ray::core::NormalSchedulingQueue * const this) (/home/hua/code/ray/src/ray/core_worker/transport/normal_scheduling_queue.cc:87)</span><br><span class="line"></span><br><span class="line">_raylet.so!ray::core::TaskReceiver::RunNormalTasksFromQueue(ray::core::TaskReceiver * const this) (/home/hua/code/ray/src/ray/core_worker/transport/task_receiver.cc:294)</span><br><span class="line"></span><br><span class="line">_raylet.so!operator()(const struct &#123;...&#125; * const __closure) (/home/hua/code/ray/src/ray/core_worker/core_worker.cc:3777)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>回调中的<code>task_handler_</code>
就是注册进去的<code>CoreWorker::ExecuteTask</code>，将这个对象封装成了一个lamda函数：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> execute_task = std::<span class="built_in">bind</span>(&amp;CoreWorker::ExecuteTask,</span><br><span class="line">                                  <span class="keyword">this</span>,</span><br><span class="line">                                  std::placeholders::_1,</span><br><span class="line">                                  std::placeholders::_2,</span><br><span class="line">                                  std::placeholders::_3,</span><br><span class="line">                                  std::placeholders::_4,</span><br><span class="line">                                  std::placeholders::_5,</span><br><span class="line">                                  std::placeholders::_6,</span><br><span class="line">                                  std::placeholders::_7,</span><br><span class="line">                                  std::placeholders::_8);</span><br></pre></td></tr></table></figure>
<p>最终调用到了<code>options_.task_execution_callback</code>，这个callback会根据语言的不同而不同，以Python为例，这个callback调用的是注册进来的一个Python方法，将Python的远程函数交还给Python解释器来执行。这部分代码在ray/python/ray/_raylet.pyx中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cdef void execute_task: return function(actor, *arguments, **kwarguments)</span><br><span class="line">cdef execute_task_with_cancellation_handler: execute_task</span><br><span class="line">cdef CRayStatus task_execution_handler: execute_task_with_cancellation_handler</span><br><span class="line">CoreWorker::__cinit__: options.task_execution_callback = task_execution_handler</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/12/25/%E6%8E%A8%E7%90%86%E5%85%A8%E5%9C%BA%E6%99%AF%E6%B4%9E%E5%AF%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="hipudding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hipudding's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | hipudding's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/12/25/%E6%8E%A8%E7%90%86%E5%85%A8%E5%9C%BA%E6%99%AF%E6%B4%9E%E5%AF%9F/" class="post-title-link" itemprop="url">推理全场景洞察</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-12-25 14:20:26 / 修改时间：14:25:58" itemprop="dateCreated datePublished" datetime="2023-12-25T14:20:26+08:00">2023-12-25</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="推理场景">推理场景</h2>
<ul>
<li><p><strong>计算机视觉：</strong>图像分类，目标检测，人脸识别，图像生成。</p></li>
<li><p><strong>自然语言处理（NLP)：</strong>翻译，语音识别，文本分类，内容审核。</p></li>
<li><p><strong>自动驾驶</strong></p></li>
<li><p><strong>生物学：</strong>医学影响分析，基因分析，蛋白质预测。</p></li>
<li><p><strong>金融：</strong>信用，风控。</p></li>
<li><p><strong>制造业：</strong>质量控制，成本控制。</p></li>
<li><p><strong>零售业：</strong>推荐广告系统，库存管理。</p></li>
<li><p><strong>能源：</strong>智能电网。</p></li>
<li><p><strong>大模型推理：</strong>LLM，多模态模型推理。</p></li>
</ul>
<h2 id="推理的一般流程">推理的一般流程</h2>
<p>以目标检测为例：</p>
<ol type="1">
<li><p><strong>预训练模型获取</strong>：从
Huggingface或者其他预训练模型平台上下载模型；</p></li>
<li><p><strong>模型转换：</strong>根据使用的推理框架，将下载的模型转换成对应的格式；</p></li>
<li><p><strong>数据预处理：</strong>视频解码，并从流中抓取图像，将图像进行裁剪，旋转，翻转，调整色彩空间，标准化等操作；</p></li>
<li><p><strong>模型推理：</strong>将处理完成的图像数据输入模型进行推理，得到推理结果；</p></li>
<li><p><strong>后处理：</strong>将模型推理结果进行处理，获取目标框，标签等信息；</p></li>
<li><p><strong>结果展示：</strong>将原始图像和推理结果进行融合，给检测的目标加上框和目标类型标签。</p></li>
</ol>
<h2 id="推理技术栈">推理技术栈</h2>
<p><strong>Nvidia</strong></p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20231116101903233.png"
alt="image-20231116101903233" />
<figcaption aria-hidden="true">image-20231116101903233</figcaption>
</figure>
<p><strong>昇腾</strong></p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20231116101849666.png"
alt="image-20231116101849666" />
<figcaption aria-hidden="true">image-20231116101849666</figcaption>
</figure>
<p>推理技术栈自下而上一般为：</p>
<ul>
<li>硬件：参与推理的硬件，例如CPU，GPU和NPU等，Nvidia目前常用的GPU为Volta-&gt;Turing-&gt;Ampere-&gt;Hopper等架构，Ascend为310系列和910系列芯片，
采用Davinci架构。</li>
<li>驱动和基础软件：此类软件包括加速卡的驱动程序，异构计算运行时（CUDA
RT, CANN
RT)，kernel开发调试工具等。除此之外，Ascend还提供了常用算子库。</li>
<li>推理引擎：推理引擎一般提供模型转换，模型优化，以及模型推理功能，并且提供运行的性能指标供性能分析和自动负载均衡。
大部分推理引擎都原生支持CUDA，对昇腾的原生支持较弱。</li>
<li>推理服务化：推理服务化工具一般提供restful和rpc接口，模型服务化部署。另外可以配合容器技术，调度技术和负载均衡等实现自动扩缩容，提高推理速度，提高资源利用率。基本上大多深度学习框架均提供了服务化部署能力，其中Triton支持多种后端，并提供了友好的接入接口。</li>
<li>行业应用：针对特定行业的预处理，pipeline或者相关的SDK用于简化行业应用的开发复杂度，甚至通过配置可以直接在行业内应用。</li>
<li>其他配套：其他配套例如预训练模型的仓库，模型调优工具，算法加速库以及边缘计算平台等。</li>
</ul>
<h2 id="推理流程中涉及的软件">推理流程中涉及的软件</h2>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20231116102732237.png"
alt="image-20231116102732237" />
<figcaption aria-hidden="true">image-20231116102732237</figcaption>
</figure>
<ul>
<li>模型预处理hub：hub不仅能够保存预训练模型，并且能够通过代码api的方式直接下载并加载模型。昇腾的Model
Zoo需要手动下载模型，Huggingface的预训练模型可以通过python
api下载和使用。</li>
<li>模型转换：ONNX是一种开发的模型格式，可以与常见的深度学习框架进行转换。除此之外，其他的框架一般提供有限的模型转换能力，大多是同一个框架内的不同模型格式的转换。</li>
<li>预处理：计算机视觉中，Nvidia自研了部分适配GPU的加速库，并且常见的OpenCV，torchvision也原生支持GPU。目前对昇腾的支持较弱，目前仅有mxBase和OpenCV实现了少量的常用接口。昇腾推理的CV预处理，还需要依赖CPU处理。自然语言处理库由于算法的特殊性，无法充分利用并行计算能力，上述库基本上都仅在CPU上运行。Nvidia提供了推荐系统大量数据并能处理能力的库NVTabular，昇腾在此方面可以使用mxRec提供的加速能力。</li>
<li>模型分析优化：推理框架一般分为优化和运行两部分，其中优化部分对传入的模型根据底层架构进行优化。并且在执行过程中可以通过组件监控模型的运行情况，以用来模型调优，或者提供弹性扩缩容能力。</li>
<li>推理框架：推理框架是推理业务的重点，不同的推理框架能力各有优劣：
<ul>
<li><strong>TensorRT (TensorRT by NVIDIA):</strong>
<ul>
<li>优点：
<ul>
<li>面向 NVIDIA GPU 的深度学习推理优化库。</li>
<li>针对高性能、低延迟的推理任务进行了优化。</li>
</ul></li>
<li>缺点：
<ul>
<li>仅适用于 NVIDIA GPU，不具备跨平台性。</li>
</ul></li>
</ul></li>
<li><strong>ONNX Runtime:</strong>
<ul>
<li>优点：
<ul>
<li>开放的模型表示格式，允许在不同框架之间共享和部署模型。</li>
<li>支持多种深度学习框架，如TensorFlow、PyTorch、Caffe等。</li>
</ul></li>
<li>缺点：
<ul>
<li>部分框架的支持可能不如原生框架的性能优越。</li>
</ul></li>
</ul></li>
<li><strong>OpenVINO</strong>
<ul>
<li>优点：
<ul>
<li>多平台支持，支持多深度学习框架。</li>
<li>针对各设备硬件进行优化，能在多种设备上高性能推理。</li>
</ul></li>
<li>缺点：
<ul>
<li>大量优化针对Intel硬件，对其他硬件厂商的优化有限。</li>
<li>开源版本功能限制，有些特性需要商业版支持。</li>
</ul></li>
</ul></li>
<li><strong>ncnn， TNN， MNN，ARMNN</strong>
<ul>
<li>优点：
<ul>
<li>面向移动端和嵌入式CPU或GPU，轻量级，弱依赖。</li>
<li>支持多种模型类型，有模型转换能力。</li>
</ul></li>
<li>缺点：
<ul>
<li>非嵌入式平台（ARMNN在非ARM平台）支持较弱。</li>
</ul></li>
</ul></li>
</ul></li>
<li>推理服务化：主流的深度学习框架基本上都提供了服务化能力，可以通过restful或者rpc接口进行模型推理。其中Triton设计更为灵活，能够方便的集成不同的后端，目前已经支持主流深度学习框架的推理服务。目前还没有支持昇腾推理框架，但是可以通过pytorch插件或者ONNX
runtime进行推理。</li>
<li>后处理：后处理将图例结果进行加工处理，并展示推理结果，所需软件与预处理大致相同。</li>
</ul>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20231116102541095.png"
alt="image-20231116102541095" />
<figcaption aria-hidden="true">image-20231116102541095</figcaption>
</figure>
<p>除了推理流程中的软件之外，还有行业应用，边缘计算，以及算法加速库。Nvidia和昇腾在这些领域均有涉及。</p>
<h2 id="总结">总结</h2>
<ol type="1">
<li>昇腾在主流深度学习框架，推理框架以及推理服务化软件中，原生支持较弱，大部分框架在设计之初均考虑GPU支持，目前已经支持昇腾的框架多为后期开发。如果框架在后端支持上设计不够友好，接入难度较高。</li>
<li>计算机视觉预处理能力与GPU能力差距较大，包括OpenCV，torchvision等开源CV软件均原生支持GPU，并且Nvidia还有自研的图像预处理库，昇腾仅支持少量高频使用的接口，并且性能还存在差距。</li>
<li>Nvidia和开源在框架，应用软件和加速库的使用上较为容易，社区活跃，文档完整规范，学习成本低。昇腾相关软件使用门槛较高，使用上相较而言较为繁琐。</li>
<li>建议在推理全流程中选择一个技术路线，做昇腾支持，在功能，性能上追平或超过友商，然后再考虑自研更适合昇腾场景的自研软件。</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/12/AscendC-vs-CUDA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="hipudding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hipudding's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | hipudding's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/12/AscendC-vs-CUDA/" class="post-title-link" itemprop="url">AscendC vs CUDA</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-12 09:35:14 / 修改时间：09:38:04" itemprop="dateCreated datePublished" datetime="2023-10-12T09:35:14+08:00">2023-10-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="什么是ascendccuda编程">什么是AscendC/CUDA编程</h2>
<blockquote>
<p>面向算子开发场景的编程语言Ascend
C，原生支持C和C++标准规范，最大化匹配用户开发习惯；通过多层接口抽象、自动并行计算、孪生调试等关键技术，极大提高算子开发效率，助力AI开发者低成本完成算子开发和模型调优部署。</p>
</blockquote>
<blockquote>
<p><strong>CUDA</strong>（<strong>C</strong>ompute
<strong>U</strong>nified <strong>D</strong>evice
<strong>A</strong>rchitecture，<strong>统一计算架构</strong>[<a
target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CUDA#cite_note-1">1]</a>）是由英伟达<a
target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/NVIDIA">NVIDIA</a>所推出的一种<a
target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/軟體">软</a><a
target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/计算机硬件">硬件</a>集成技术，是该公司对于<a
target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/GPGPU">GPGPU</a>的正式名称。透过这个技术，用户可利用NVIDIA的<a
target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/GPU">GPU</a>进行<a
target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/图像处理">图像处理</a>之外的运算，亦是首次可以利用GPU作为C-编译器的开发环境。</p>
</blockquote>
<p><strong>一句话概括：AscendC/CUDA就是使用昇腾设备/GPU设备的编程接口。</strong></p>
<h2 id="与我们熟悉的编程有什么区别">与我们熟悉的编程有什么区别</h2>
<p><strong>内存</strong></p>
<p>Host编程仅考虑主存，所有的内存操作对象均为主存，不需要考虑CPU缓存，寄存器等，这些对程序开发完全透明。</p>
<p>Device编程需要了解每个运行单元能访问的内存类型，可以理解要手动管理一级二级缓存，例如，AscendC变成框架下，内存的类型有：</p>
<table>
<colgroup>
<col style="width: 10%" />
<col style="width: 89%" />
</colgroup>
<thead>
<tr class="header">
<th>枚举值</th>
<th>具体含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GM</td>
<td>Global Memory，对应AI Core的外部存储。</td>
</tr>
<tr class="even">
<td>VECIN</td>
<td>用于矢量计算，搬入数据的存放位置，在数据搬入Vector计算单元时使用此位置</td>
</tr>
<tr class="odd">
<td>VECOUT</td>
<td>用于矢量计算，搬出数据的存放位置，在将Vector计算单元结果搬出时使用此位置</td>
</tr>
<tr class="even">
<td>VECCALC</td>
<td>用于矢量计算/矩阵计算，在计算需要临时变量时使用此位置</td>
</tr>
<tr class="odd">
<td>A1</td>
<td>用于矩阵计算，存放整块A矩阵，可类比CPU多级缓存中的二级缓存</td>
</tr>
<tr class="even">
<td>B1</td>
<td>用于矩阵计算，存放整块B矩阵，可类比CPU多级缓存中的二级缓存</td>
</tr>
<tr class="odd">
<td>A2</td>
<td>用于矩阵计算，存放切分后的小块A矩阵，可类比CPU多级缓存中的一级缓存</td>
</tr>
<tr class="even">
<td>B2</td>
<td>用于矩阵计算，存放切分后的小块B矩阵，可类比CPU多级缓存中的一级缓存</td>
</tr>
<tr class="odd">
<td>CO1</td>
<td>用于矩阵计算，存放小块结果C矩阵，可理解为Cube Out</td>
</tr>
<tr class="even">
<td>CO2</td>
<td>用于矩阵计算，存放整块结果C矩阵，可理解为Cube Out</td>
</tr>
</tbody>
</table>
<p>不同的处理单元，不同的处理步骤访问的内存是不同的，需要开发者自行处理。</p>
<p><strong>编程模型</strong></p>
<p>Host编程一般为串行的，如果想启用并行处理需要手动开启多线程，或者SIMD(Single
Instruction, Multiple Data)。</p>
<p>Device编程一般为并行，SPMD(Single-Program
Multiple-Data)。在设备上启动多线程，共同处理一份数据。Device编程代码分为两个部分，Host侧执行的一般代码和在设备上执行的核函数(kernel
function)。</p>
<p>AscendC还需要注意的是流水线编程范式，流水线编程主要是为了加速数据拷贝，Device处理以及数据拷回的流程。因为DMA搬运单元，各个计算单元是并行工作的，使用流水线能够提高设备单元的使用率。</p>
<h2 id="device-的内部结构抽象">Device 的内部结构抽象</h2>
<p><strong>Ascend AI Core 内部抽象结构</strong></p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/2021051922433521.png"
alt="达芬奇架构" />
<figcaption aria-hidden="true">达芬奇架构</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/zh-cn_image_0000001706909793.png"
alt="AI Core抽象结构" />
<figcaption aria-hidden="true">AI Core抽象结构</figcaption>
</figure>
<p><strong>CUDA核心内部抽象结构</strong></p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/70.png"
alt="CUDA核心结构" />
<figcaption aria-hidden="true">CUDA核心结构</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/70-20231010170118685.png"
alt="CUDA核心结构" />
<figcaption aria-hidden="true">CUDA核心结构</figcaption>
</figure>
<p><strong>AI Core和Stream Multiprocessor的最主要区别是：</strong></p>
<ul>
<li><p><strong>AI
Core中是专用处理单元，包括Vector和Cube，分别用户向量和矩阵运算，能用向量和矩阵运算的操作效率会很高。</strong></p></li>
<li><p><strong>Stream
Multiprocessor基本上都是大量的int32核心，float32核心或者双精度核心，由于数量众多，所以并行能力更强。</strong></p></li>
</ul>
<h2 id="ascendc编程和cuda编程对比">AscendC编程和CUDA编程对比</h2>
<p><strong>AscendC</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> __CCE_KT_TEST__</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;acl/acl.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tikicpulib.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;data_loader.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __CCE_KT_TEST__</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __aicore__</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __aicore__ [aicore]</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int</span> BUFFER_NUM = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int</span> BLOCK_DIM = <span class="number">16</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*****************************Copy scalar to ubuf*****************************/</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">FlipTilingData</span> &#123;</span><br><span class="line">  <span class="type">uint32_t</span> height;</span><br><span class="line">  <span class="type">uint32_t</span> width;</span><br><span class="line">  <span class="type">uint32_t</span> channel;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> __aicore__ <span class="type">int32_t</span> <span class="title">align32</span><span class="params">(<span class="type">int32_t</span> n)</span> </span>&#123; <span class="keyword">return</span> ((n + <span class="number">31</span>) &amp; ~<span class="number">31</span>); &#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> __aicore__ <span class="type">int32_t</span> <span class="title">AlignDiv32</span><span class="params">(<span class="type">int32_t</span> n)</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">align32</span>(n) / <span class="number">32</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CONVERT_TILING_DATA(tilingStruct, tilingDataPointer, tilingPointer) \</span></span><br><span class="line"><span class="meta">  __ubuf__ tilingStruct* tilingDataPointer =                                \</span></span><br><span class="line"><span class="meta">      reinterpret_cast<span class="string">&lt;__ubuf__ tilingStruct*&gt;</span>(                             \</span></span><br><span class="line"><span class="meta">          (__ubuf__ uint8_t*)(tilingPointer));</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __CCE_KT_TEST__</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INIT_TILING_DATA(tilingStruct, tilingDataPointer, tilingPointer) \</span></span><br><span class="line"><span class="meta">  CONVERT_TILING_DATA(tilingStruct, tilingDataPointer, tilingPointer);</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INIT_TILING_DATA(tilingStruct, tilingDataPointer, tilingPointer) \</span></span><br><span class="line"><span class="meta">  __ubuf__ uint8_t* tilingUbPointer = (__ubuf__ uint8_t*)get_imm(0);     \</span></span><br><span class="line"><span class="meta">  copy_gm_to_ubuf(((__ubuf__ uint8_t*)(tilingUbPointer)),                \</span></span><br><span class="line"><span class="meta">                  ((__gm__ uint8_t*)(tilingPointer)), 0, 1,              \</span></span><br><span class="line"><span class="meta">                  AlignDiv32(sizeof(tilingStruct)), 0, 0);               \</span></span><br><span class="line"><span class="meta">  CONVERT_TILING_DATA(tilingStruct, tilingDataPointer, tilingUbPointer); \</span></span><br><span class="line"><span class="meta">  pipe_barrier(PIPE_ALL);</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GET_TILING_DATA(tilingData, tilingPointer) \</span></span><br><span class="line"><span class="meta">  INIT_TILING_DATA(FlipTilingData, tilingData, tilingPointer);</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CHECK_ACL(x)                                                    \</span></span><br><span class="line"><span class="meta">  do &#123;                                                                  \</span></span><br><span class="line"><span class="meta">    aclError __ret = x;                                                 \</span></span><br><span class="line"><span class="meta">    <span class="keyword">if</span> (__ret != ACL_ERROR_NONE) &#123;                                      \</span></span><br><span class="line"><span class="meta">      std::cerr &lt;&lt; __FILE__ &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; __LINE__ &lt;&lt; <span class="string">&quot; aclError:&quot;</span> &lt;&lt; __ret \</span></span><br><span class="line"><span class="meta">                &lt;&lt; std::endl;                                           \</span></span><br><span class="line"><span class="meta">    &#125;                                                                   \</span></span><br><span class="line"><span class="meta">  &#125; while (0);</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*******************************Kernel function*******************************/</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelFlip</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelFlip</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">  <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR input, GM_ADDR output, <span class="type">uint32_t</span> _height,</span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="type">uint32_t</span> _width, <span class="type">uint32_t</span> _channel)</span> </span>&#123;</span><br><span class="line">    <span class="type">uint32_t</span> blockNum = <span class="built_in">GetBlockNum</span>();</span><br><span class="line">    <span class="type">uint32_t</span> blockIdx = <span class="built_in">GetBlockIdx</span>();</span><br><span class="line"></span><br><span class="line">    rowLength = _height / blockNum;</span><br><span class="line">    startRowIdx = blockIdx * rowLength;</span><br><span class="line">    <span class="keyword">if</span> (startRowIdx + rowLength &gt; _height) &#123;</span><br><span class="line">      rowLength = _height - startRowIdx;</span><br><span class="line">    &#125;</span><br><span class="line">    width = _width;</span><br><span class="line">    height = _height;</span><br><span class="line">    channel = _channel;</span><br><span class="line">    rowSize = width * channel;</span><br><span class="line">    <span class="type">uint32_t</span> bufferSize = <span class="built_in">align32</span>(rowSize * <span class="built_in">sizeof</span>(<span class="type">uint8_t</span>));</span><br><span class="line"></span><br><span class="line">    inputGM.<span class="built_in">SetGlobalBuffer</span>((__gm__ <span class="type">uint8_t</span>*)input + startRowIdx * rowSize,</span><br><span class="line">                            rowLength * rowSize);</span><br><span class="line">    outputGM.<span class="built_in">SetGlobalBuffer</span>((__gm__ <span class="type">uint8_t</span>*)output + startRowIdx * rowSize,</span><br><span class="line">                             rowLength * rowSize);</span><br><span class="line">    pipe.<span class="built_in">InitBuffer</span>(inQueue, BUFFER_NUM, bufferSize);</span><br><span class="line">    pipe.<span class="built_in">InitBuffer</span>(outQueue, BUFFER_NUM, bufferSize);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; rowLength; i++) &#123;</span><br><span class="line">      <span class="built_in">CopyIn</span>(i);</span><br><span class="line">      <span class="built_in">Compute</span>(i);</span><br><span class="line">      <span class="built_in">CopyOut</span>(i);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> loop)</span> </span>&#123;</span><br><span class="line">    LocalTensor&lt;<span class="type">uint8_t</span>&gt; local = inQueue.<span class="built_in">AllocTensor</span>&lt;<span class="type">uint8_t</span>&gt;();</span><br><span class="line">    <span class="built_in">DataCopy</span>(local, inputGM[loop * rowSize], rowSize);</span><br><span class="line">    inQueue.<span class="built_in">EnQue</span>(local);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> loop)</span> </span>&#123;</span><br><span class="line">    LocalTensor&lt;<span class="type">uint8_t</span>&gt; inputLocal = inQueue.<span class="built_in">DeQue</span>&lt;<span class="type">uint8_t</span>&gt;();</span><br><span class="line">    LocalTensor&lt;<span class="type">uint8_t</span>&gt; outputLocal = outQueue.<span class="built_in">AllocTensor</span>&lt;<span class="type">uint8_t</span>&gt;();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; width; i++) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int32_t</span> c = <span class="number">0</span>; c &lt; channel; c++) &#123;</span><br><span class="line">        outputLocal.<span class="built_in">SetValue</span>(</span><br><span class="line">            i * channel + c,</span><br><span class="line">            inputLocal.<span class="built_in">GetValue</span>((width - i - <span class="number">1</span>) * channel + c));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    outQueue.<span class="built_in">EnQue</span>&lt;<span class="type">uint8_t</span>&gt;(outputLocal);</span><br><span class="line">    inQueue.<span class="built_in">FreeTensor</span>(inputLocal);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> loop)</span> </span>&#123;</span><br><span class="line">    LocalTensor&lt;<span class="type">uint8_t</span>&gt; local = outQueue.<span class="built_in">DeQue</span>&lt;<span class="type">uint8_t</span>&gt;();</span><br><span class="line">    <span class="built_in">DataCopy</span>(outputGM[loop * rowSize], local, rowSize);</span><br><span class="line">    outQueue.<span class="built_in">FreeTensor</span>(local);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  TPipe pipe;</span><br><span class="line">  TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueue;</span><br><span class="line">  TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueue;</span><br><span class="line">  GlobalTensor&lt;<span class="type">uint8_t</span>&gt; inputGM, outputGM;</span><br><span class="line">  <span class="type">uint32_t</span> startRowIdx, rowLength, rowSize, height, width, channel;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*******************************kernel interface******************************/</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">flip</span><span class="params">(GM_ADDR input, GM_ADDR output,</span></span></span><br><span class="line"><span class="params"><span class="function">                                           GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">GET_TILING_DATA</span>(tilingData, tiling);</span><br><span class="line">  KernelFlip op;</span><br><span class="line">  op.<span class="built_in">Init</span>(input, output, tilingData-&gt;height, tilingData-&gt;width,</span><br><span class="line">          tilingData-&gt;channel);</span><br><span class="line">  op.<span class="built_in">Process</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> __CCE_KT_TEST__</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">flip_do</span><span class="params">(<span class="type">uint32_t</span> blockDim, <span class="type">void</span>* l2ctrl, <span class="type">void</span>* stream, <span class="type">uint8_t</span>* input,</span></span></span><br><span class="line"><span class="params"><span class="function">             <span class="type">uint8_t</span>* output, <span class="type">uint8_t</span>* tiling)</span> </span>&#123;</span><br><span class="line">  flip&lt;&lt;&lt;blockDim, l2ctrl, stream&gt;&gt;&gt;(input, output, tiling);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/***********************************caller************************************/</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">main</span><span class="params">(<span class="type">int32_t</span> argc, <span class="type">char</span>* argv[])</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (argc != <span class="number">2</span>) &#123;</span><br><span class="line">    std::cerr &lt;&lt; <span class="string">&quot;usage: &quot;</span> &lt;&lt; argv[<span class="number">0</span>] &lt;&lt; <span class="string">&quot; path/to/datafile&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">uint32_t</span> blockDim = BLOCK_DIM;</span><br><span class="line">  <span class="type">uint32_t</span> height, width, channel;</span><br><span class="line">  <span class="type">uint8_t</span>* data = <span class="built_in">readFile</span>(argv[<span class="number">1</span>], height, width, channel);</span><br><span class="line">  <span class="type">const</span> <span class="type">char</span>* resultFile = std::<span class="built_in">string</span>(argv[<span class="number">1</span>]).<span class="built_in">append</span>(<span class="string">&quot;.ret&quot;</span>).<span class="built_in">c_str</span>();</span><br><span class="line"></span><br><span class="line">  <span class="type">uint32_t</span> dataSize = width * height * channel * <span class="built_in">sizeof</span>(<span class="type">uint8_t</span>);</span><br><span class="line">  <span class="type">size_t</span> inputByteSize = dataSize;</span><br><span class="line">  <span class="type">size_t</span> outputByteSize = dataSize;</span><br><span class="line">  <span class="type">size_t</span> tilingSize = <span class="built_in">sizeof</span>(FlipTilingData);</span><br><span class="line"></span><br><span class="line">  <span class="type">uint8_t</span> *inputHost, *outputHost, *tilingHost;</span><br><span class="line">  <span class="type">uint32_t</span> shape[]&#123;height, width, channel&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __CCE_KT_TEST__</span></span><br><span class="line">  inputHost = (<span class="type">uint8_t</span>*)AscendC::<span class="built_in">GmAlloc</span>(inputByteSize);</span><br><span class="line">  outputHost = (<span class="type">uint8_t</span>*)AscendC::<span class="built_in">GmAlloc</span>(outputByteSize);</span><br><span class="line">  tilingHost = (<span class="type">uint8_t</span>*)AscendC::<span class="built_in">GmAlloc</span>(tilingSize);</span><br><span class="line">  <span class="built_in">memcpy</span>(tilingHost, shape, tilingSize);</span><br><span class="line">  <span class="built_in">memcpy</span>(inputHost, data, dataSize);</span><br><span class="line"></span><br><span class="line">  AscendC::<span class="built_in">SetKernelMode</span>(KernelMode::AIV_MODE);</span><br><span class="line">  <span class="built_in">ICPU_RUN_KF</span>(flip, blockDim, inputHost, outputHost, tilingHost);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">writeFile</span>(resultFile, height, width, channel, outputHost);</span><br><span class="line"></span><br><span class="line">  AscendC::<span class="built_in">GmFree</span>((<span class="type">void</span>*)inputHost);</span><br><span class="line">  AscendC::<span class="built_in">GmFree</span>((<span class="type">void</span>*)outputHost);</span><br><span class="line">  AscendC::<span class="built_in">GmFree</span>((<span class="type">void</span>*)tilingHost);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclInit</span>(<span class="literal">nullptr</span>));</span><br><span class="line">  aclrtContext context;</span><br><span class="line">  <span class="type">int32_t</span> deviceId = <span class="number">0</span>;</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtSetDevice</span>(deviceId));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtCreateContext</span>(&amp;context, deviceId));</span><br><span class="line">  aclrtStream stream = <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtCreateStream</span>(&amp;stream));</span><br><span class="line"></span><br><span class="line">  <span class="type">uint8_t</span> *inputDevice, *outputDevice, *tilingDevice;</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtMallocHost</span>((<span class="type">void</span>**)(&amp;tilingHost), tilingSize));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtMallocHost</span>((<span class="type">void</span>**)(&amp;inputHost), inputByteSize));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtMallocHost</span>((<span class="type">void</span>**)(&amp;outputHost), outputByteSize));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtMalloc</span>((<span class="type">void</span>**)&amp;inputDevice, inputByteSize,</span><br><span class="line">                        ACL_MEM_MALLOC_HUGE_FIRST));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtMalloc</span>((<span class="type">void</span>**)&amp;outputDevice, outputByteSize,</span><br><span class="line">                        ACL_MEM_MALLOC_HUGE_FIRST));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtMalloc</span>((<span class="type">void</span>**)&amp;tilingDevice, tilingSize,</span><br><span class="line">                        ACL_MEM_MALLOC_HUGE_FIRST));</span><br><span class="line"></span><br><span class="line">  <span class="built_in">memcpy</span>(tilingHost, shape, tilingSize);</span><br><span class="line">  <span class="built_in">memcpy</span>(inputHost, data, dataSize);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtMemcpy</span>(inputDevice, inputByteSize, inputHost, inputByteSize,</span><br><span class="line">                        ACL_MEMCPY_HOST_TO_DEVICE));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtMemcpy</span>(tilingDevice, tilingSize, tilingHost, tilingSize,</span><br><span class="line">                        ACL_MEMCPY_HOST_TO_DEVICE));</span><br><span class="line"></span><br><span class="line">  <span class="built_in">flip_do</span>(blockDim, <span class="literal">nullptr</span>, stream, inputDevice, outputDevice, tilingDevice);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtSynchronizeStream</span>(stream));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtMemcpy</span>(outputHost, outputByteSize, outputDevice,</span><br><span class="line">                        outputByteSize, ACL_MEMCPY_DEVICE_TO_HOST));</span><br><span class="line">  <span class="built_in">writeFile</span>(resultFile, height, width, channel, outputHost);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtFree</span>(inputDevice));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtFree</span>(outputDevice));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtFree</span>(tilingDevice));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtFreeHost</span>(inputHost));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtFreeHost</span>(outputHost));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtFreeHost</span>(tilingHost));</span><br><span class="line"></span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtDestroyStream</span>(stream));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtDestroyContext</span>(context));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclrtResetDevice</span>(deviceId));</span><br><span class="line">  <span class="built_in">CHECK_ACL</span>(<span class="built_in">aclFinalize</span>());</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">  <span class="built_in">free</span>(data);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/zh-cn_image_0000001706789009.png"
alt="流水线示例" />
<figcaption aria-hidden="true">流水线示例</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/zh-cn_image_0000001658510374.png"
alt="数据切分示例" />
<figcaption aria-hidden="true">数据切分示例</figcaption>
</figure>
<p><strong>CUDA</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;data_loader.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">flip</span><span class="params">(<span class="type">uint8_t</span>* input, <span class="type">uint8_t</span>* output, <span class="type">uint32_t</span> height,</span></span></span><br><span class="line"><span class="params"><span class="function">                     <span class="type">uint32_t</span> width, <span class="type">uint32_t</span> channel)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> rowIdx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line">  <span class="type">int</span> rowSize = width * channel;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> row = rowIdx; row &lt; height; row += stride) &#123;</span><br><span class="line">    <span class="type">int</span> startOffset = row * rowSize;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> idx = <span class="number">0</span>; idx &lt; width; idx++) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> c = <span class="number">0</span>; c &lt; channel; c++) &#123;</span><br><span class="line">        output[startOffset + idx * channel + c] =</span><br><span class="line">            input[startOffset + (width - idx - <span class="number">1</span>) * channel + c];</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int32_t</span> argc, <span class="type">char</span>* argv[])</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (argc != <span class="number">2</span>) &#123;</span><br><span class="line">    std::cerr &lt;&lt; <span class="string">&quot;usage: &quot;</span> &lt;&lt; argv[<span class="number">0</span>] &lt;&lt; <span class="string">&quot; path/to/datafile&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">uint32_t</span> height, width, channel;</span><br><span class="line">  <span class="type">char</span> fileName[<span class="number">256</span>], resultFile[<span class="number">256</span>];</span><br><span class="line">  <span class="built_in">memset</span>(fileName, <span class="number">0</span>, <span class="number">256</span>);</span><br><span class="line">  <span class="built_in">memset</span>(resultFile, <span class="number">0</span>, <span class="number">256</span>);</span><br><span class="line">  <span class="built_in">strcpy</span>(fileName, argv[<span class="number">1</span>]);</span><br><span class="line">  <span class="built_in">strcat</span>(resultFile, fileName);</span><br><span class="line">  <span class="built_in">strcat</span>(resultFile, <span class="string">&quot;.ret&quot;</span>);</span><br><span class="line">  <span class="type">uint8_t</span>* data = <span class="built_in">readFile</span>(fileName, height, width, channel);</span><br><span class="line"></span><br><span class="line">  <span class="type">uint32_t</span> dataSize = width * height * channel * <span class="built_in">sizeof</span>(<span class="type">uint8_t</span>);</span><br><span class="line">  <span class="type">size_t</span> inputByteSize = dataSize;</span><br><span class="line">  <span class="type">size_t</span> outputByteSize = dataSize;</span><br><span class="line">  <span class="type">uint8_t</span> *input, *output;</span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;input, inputByteSize);</span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;output, outputByteSize);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">memcpy</span>(input, data, inputByteSize);</span><br><span class="line"></span><br><span class="line">  <span class="function">dim3 <span class="title">blockSize</span><span class="params">(<span class="number">256</span>)</span></span>;</span><br><span class="line">  <span class="function">dim3 <span class="title">gridSize</span><span class="params">((height + blockSize.x - <span class="number">1</span>) / blockSize.x)</span></span>;</span><br><span class="line"></span><br><span class="line">  flip&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(input, output, height, width, channel);</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line"></span><br><span class="line">  <span class="built_in">writeFile</span>(resultFile, height, width, channel, output);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(input);</span><br><span class="line">  <span class="built_in">cudaFree</span>(output);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/29/Pytorch-DDP%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="hipudding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hipudding's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | hipudding's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/29/Pytorch-DDP%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">Pytorch DDP原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-06-29 17:10:02 / 修改时间：17:13:19" itemprop="dateCreated datePublished" datetime="2023-06-29T17:10:02+08:00">2023-06-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>DDP=分布式数据并行(DISTRIBUTED DATA
PARALLEL)，和DP一样也是一种数据并行的方法，详细文档可以参考<a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/ddp.html">官方手册</a></p>
<h2 id="ddp使用">DDP使用</h2>
<p>以下是使用NPU进行2个节点并行的示例代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch_npu</span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">import</span> torch.multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel <span class="keyword">as</span> DDP</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">example</span>(<span class="params">rank, world_size</span>):</span><br><span class="line">    torch.npu.set_device(rank)</span><br><span class="line">    device = torch.device(<span class="string">&#x27;npu&#x27;</span>)</span><br><span class="line">    <span class="comment"># create default process group</span></span><br><span class="line">    dist.init_process_group(<span class="string">&quot;hccl&quot;</span>, rank=rank, world_size=world_size)</span><br><span class="line">    <span class="comment"># create local model</span></span><br><span class="line">    model = nn.Linear(<span class="number">10</span>, <span class="number">10</span>).to(device)</span><br><span class="line">    <span class="comment"># construct DDP model</span></span><br><span class="line">    ddp_model = DDP(model, device_ids=[rank])</span><br><span class="line">    <span class="comment"># define loss function and optimizer</span></span><br><span class="line">    loss_fn = nn.MSELoss()</span><br><span class="line">    optimizer = optim.SGD(ddp_model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">    <span class="comment"># forward pass</span></span><br><span class="line">    outputs = ddp_model(torch.randn(<span class="number">20</span>, <span class="number">10</span>).to(device))</span><br><span class="line">    labels = torch.randn(<span class="number">20</span>, <span class="number">10</span>).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward pass</span></span><br><span class="line">    loss = loss_fn(outputs, labels)</span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># update parameters</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    world_size = <span class="number">2</span></span><br><span class="line">    mp.spawn(example,</span><br><span class="line">        args=(world_size,),</span><br><span class="line">        nprocs=world_size,</span><br><span class="line">        join=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># Environment variables which need to be</span></span><br><span class="line">    <span class="comment"># set when using c10d&#x27;s default &quot;env&quot;</span></span><br><span class="line">    <span class="comment"># initialization mode.</span></span><br><span class="line">    os.environ[<span class="string">&quot;MASTER_ADDR&quot;</span>] = <span class="string">&quot;localhost&quot;</span></span><br><span class="line">    os.environ[<span class="string">&quot;MASTER_PORT&quot;</span>] = <span class="string">&quot;29500&quot;</span></span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="ddp原理">DDP原理</h2>
<h3 id="相关文件">相关文件</h3>
<table>
<colgroup>
<col style="width: 57%" />
<col style="width: 42%" />
</colgroup>
<thead>
<tr class="header">
<th>文件</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>torch/nn/parallel/distributed.py</td>
<td>DistributedDataParallel类实现</td>
</tr>
<tr class="even">
<td>torch/csrc/distributed/c10d/reducer.cpp</td>
<td>DDP reduce类实现文件</td>
</tr>
<tr class="odd">
<td>torch/csrc/distributed/c10d/reducer.hpp</td>
<td>DDP reduce接口文件</td>
</tr>
<tr class="even">
<td>torch/csrc/distributed/c10d/init.cpp</td>
<td>python C插件注册文件</td>
</tr>
</tbody>
</table>
<h3 id="进程交互">进程交互</h3>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20230629163126602.png"
alt="image-20230629163126602" />
<figcaption aria-hidden="true">image-20230629163126602</figcaption>
</figure>
<ul>
<li>主线程通过torch.multiprocessing，fork出新的进程，满足word_size的要求，然后各个线程独立运行，主进程将自己的host和port放到环境变量中共子进程使用。</li>
<li>各个进程<strong><font color='orange'>初始化process
group</font></strong>，这些进程属于同一个进程组。</li>
<li>每个进程分别创建模型，DDP对象，定义loss函数和优化器。</li>
<li>创建DDP对象时，主进程会<strong><font color="red">同步模型参数</font></strong>，这一步完成后，各个进程的模型一致。</li>
<li>每个模型输入部分数据，这些数据需要调用者自行分割，可以使用DistributedSampler。</li>
<li>然后执行模型的训练过程，每次backward执行完后，调用注册的reducer
hook函数，做<strong><font color='green'>梯度聚合</font></strong>。</li>
</ul>
<h3 id="reducer">Reducer</h3>
<p>普通模型的DDP，除了每次反向执行后的梯度同步之外，进程之间没有其他通信的需求。DDP构造时，会在每个模型参数上配置回调函数(autograd_hook)，当参数的梯度计算完成后，会调用这个回调函数。为了能够一边计算，一边同步梯度数据，DDP将相邻参数分组，每个组叫一个bucket。</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/72401724-d296d880-371a-11ea-90ab-737f86543df9.png"
alt="ddp_grad_sync.png" />
<figcaption aria-hidden="true">ddp_grad_sync.png</figcaption>
</figure>
<p>这是参数分组和allreduce的官方示意图，回调函数的执行流程如下：</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20230629170221846.png"
alt="image-20230629170221846" />
<figcaption aria-hidden="true">image-20230629170221846</figcaption>
</figure>
<ul>
<li>每个参数梯度计算完成后，均会调用回调函数，该回调函数会将参数标记为ready。</li>
<li>然后检查bucket中的pending是否为0，也就是bucket的参数是否全部完成梯度计算，如果完成，则准备进行一步all
reduce。</li>
<li>all
reduce是一个异步方法，任务执行后不阻塞，继续执行。（如果某个进程的当前bucket没有执行完成，dist
backend会等待，执行完成后异步返回）。</li>
<li>当所有的bucket都发起all reduce后，等待每个bucket的all
reduce结果，所有结果都返回后，完成本次backward。</li>
</ul>
<h2 id="参考">参考</h2>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/ddp.html">DISTRIBUTED
DATA PARALLEL</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/187610959">原创 深度 PyTorch
DDP系列第二篇：实现原理与源代码解析</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/21/Pytorch-DP%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="hipudding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hipudding's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | hipudding's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/21/Pytorch-DP%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">Pytorch DP原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-06-21 15:50:59" itemprop="dateCreated datePublished" datetime="2023-06-21T15:50:59+08:00">2023-06-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-06-26 10:15:22" itemprop="dateModified" datetime="2023-06-26T10:15:22+08:00">2023-06-26</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>DP(DataParallel)=数据并行，DP框架会将数据切片，然后模型拷贝，并在不同的backend上并行执行。<a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html?highlight=data+parallel#torch.nn.DataParallel">官方手册说明</a></p>
<h2 id="dp使用">DP使用</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = LinearModel()</span><br><span class="line">model = torch.nn.DataParallel(model,device_ids=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">criterion = torch.nn.MSELoss(size_average=<span class="literal">False</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<p>从代码中看到，DP仅支持cuda，xpu或者昇腾，并不支持cpu。</p>
<h2 id="dp原理">DP原理</h2>
<h3 id="相关文件">相关文件</h3>
<table>
<colgroup>
<col style="width: 45%" />
<col style="width: 54%" />
</colgroup>
<thead>
<tr class="header">
<th>文件</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>torch/nn/parallel/data_parallel.py</td>
<td>DP类实现</td>
</tr>
<tr class="even">
<td>torch/nn/parallel/_functions.py</td>
<td>DP中使用的自定义autograd Function</td>
</tr>
<tr class="odd">
<td>torch/nn/parallel/comm.py</td>
<td>线程间数据传递接口，例如，gather,scatter等</td>
</tr>
<tr class="even">
<td>torch/nn/parallel/replicate.py</td>
<td>模型拷贝相关</td>
</tr>
<tr class="odd">
<td>torch/nn/parallel/parallel_apply.py</td>
<td>多线程执行模型</td>
</tr>
<tr class="even">
<td>torch/nn/parallel/scatter_gather.py</td>
<td>scatter和gather的封装</td>
</tr>
<tr class="odd">
<td>torch/csrc/cuda/python_comm.cpp</td>
<td>C语言实现的数据传递函数extension注册</td>
</tr>
<tr class="even">
<td>torch/csrc/cuda/comm.cpp</td>
<td>C语言的数据传递实现</td>
</tr>
</tbody>
</table>
<h3 id="基本原理">基本原理</h3>
<p>DP基于单机多卡，所有的卡都参与训练。相对于非数据并行训练来说，DP会将一个batch数据切分为更小的batch，将数据复制到每一张计算的卡上，然后复制模型到所有的卡上，进行多线程执行，Forward计算完成后，会在device[0]上收集到一组预测值。device[0]计算loss，然后执行Backward计算梯度。（<strong>计算Backward没有看到创建线程的过程，单线程执行？？</strong>）</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/v2-5c5b0d8e3d7d6653a9ebd47bac93090c_720w.webp"
alt="DP原理图" />
<figcaption aria-hidden="true">DP原理图</figcaption>
</figure>
<h3 id="dp-wapper">DP wapper</h3>
<p>回顾DP使用方法，参与数据并行的模型进需要使用DataParalle包一层即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = torch.nn.DataParallel(model,device_ids=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>可以理解，下图就是上述代码的实现，DP就是在原本的模型执行之前增加了数据切分(Scatter)，模型复制(Broadcast)，然后将模型的并行执行结果进行合并(Gather)。</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20230621152641246.png"
alt="image-20230621152641246" />
<figcaption aria-hidden="true">image-20230621152641246</figcaption>
</figure>
<h3 id="数据传递">数据传递</h3>
<p>DP的Forward函数核心代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, *inputs: <span class="type">Any</span>, **kwargs: <span class="type">Any</span></span>) -&gt; <span class="type">Any</span>:</span><br><span class="line">	    ...</span><br><span class="line">      <span class="comment"># 训练数据切分，并拷贝到每一个卡上</span></span><br><span class="line">      inputs, module_kwargs = self.scatter(inputs, kwargs, self.device_ids)</span><br><span class="line">      </span><br><span class="line">      ...</span><br><span class="line">      <span class="comment"># 模型数据拷贝到每一个卡上</span></span><br><span class="line">      replicas = self.replicate(self.module, self.device_ids[:<span class="built_in">len</span>(inputs)])</span><br><span class="line">      <span class="comment"># 每张卡启动一个线程执行，每个线程执行模型的forward函数</span></span><br><span class="line">      outputs = self.parallel_apply(replicas, inputs, module_kwargs)</span><br><span class="line">      <span class="comment"># 集合所有线程的预测结果</span></span><br><span class="line">      <span class="keyword">return</span> self.gather(outputs, self.output_device)</span><br></pre></td></tr></table></figure>
<p>由于是单机单进程，所以数据的拷贝过程相对简单，以上述代码的scatter和broadcast为例，数据切分，然后将切分后的数据移动到指定设备上。但是Tensor还是在同一个数组中。</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20230626101410741.png"
alt="image-20230626101410741" />
<figcaption aria-hidden="true">image-20230626101410741</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20230621152441395.png"
alt="image-20230621152441395" />
<figcaption aria-hidden="true">image-20230621152441395</figcaption>
</figure>
<h3 id="自定义自动梯度方法">自定义自动梯度方法</h3>
<p>Pytorch实现了自动梯度计算，除了官方实现的梯度计算之外，还能够自定义梯度计算方法，具体描述参考<a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/extending.html#extending-torch-autograd">官方说明</a>。以下是代码中对Function类的使用举例说明：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Examples::</span><br><span class="line"></span><br><span class="line">    &gt;&gt;&gt; <span class="comment"># xdoctest: +REQUIRES(env:TORCH_DOCTEST_AUTOGRAD)</span></span><br><span class="line">    &gt;&gt;&gt; <span class="keyword">class</span> <span class="title class_">Exp</span>(<span class="title class_ inherited__">Function</span>):</span><br><span class="line">    &gt;&gt;&gt;     @<span class="built_in">staticmethod</span></span><br><span class="line">    &gt;&gt;&gt;     <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, i</span>):</span><br><span class="line">    &gt;&gt;&gt;         result = i.exp()</span><br><span class="line">    &gt;&gt;&gt;         ctx.save_for_backward(result)</span><br><span class="line">    &gt;&gt;&gt;         <span class="keyword">return</span> result</span><br><span class="line">    &gt;&gt;&gt;</span><br><span class="line">    &gt;&gt;&gt;     @<span class="built_in">staticmethod</span></span><br><span class="line">    &gt;&gt;&gt;     <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_output</span>):</span><br><span class="line">    &gt;&gt;&gt;         result, = ctx.saved_tensors</span><br><span class="line">    &gt;&gt;&gt;         <span class="keyword">return</span> grad_output * result</span><br><span class="line">    &gt;&gt;&gt;</span><br><span class="line">    &gt;&gt;&gt; <span class="comment"># Use it by calling the apply method:</span></span><br><span class="line">    &gt;&gt;&gt; <span class="comment"># xdoctest: +SKIP</span></span><br><span class="line">    &gt;&gt;&gt; output = Exp.apply(<span class="built_in">input</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>实现自定义自动梯度方法，需要继承Function类，并实现forward和backward方法，并且这两个方法均是静态的。使用自定义自动梯度方法的时候，不应该调用forward，而是调用Exp.apply，这样会返回forward的结果。相当于自己定义了算子的前向和后向的处理方法。当在执行反向传播的时候，会按反顺序调用自定义自动梯度方法的backward方法。</p>
<p>DP实现了三个自定义自动梯度方法，分别是Broadcast，Gather和Scatter，其反向传播方法内分别调用了Reduce_add，Scatter和Gather，即forward和backward中的动作是成对的。</p>
<h3 id="训练流程">训练流程</h3>
<p><strong>正向</strong></p>
<ul>
<li>①：将输入的一个batch切分成三个更小的batch</li>
<li>②：将模型的参数复制三份，分别发送到三个device上</li>
<li>③：启动三个线程，每个线程在不同的device上进行原始模型的前向计算</li>
<li>④：将三个线程的输出结果拼接到一起</li>
</ul>
<p><strong>Loss</strong></p>
<ul>
<li>在device[0]上计算Loss</li>
</ul>
<p><strong>反向</strong></p>
<ul>
<li>④：将Loss切分，分别发送给对应的模型</li>
<li>③：执行三个模型的backward方法，更新梯度（<strong>Backward
Engine多线程处理</strong>）</li>
<li>②：将三个模型上的梯度相加，并储存到Original
Module中（<strong>直接相加？</strong>）</li>
<li>①：将三个模型的梯度信息拼接到一起</li>
</ul>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20230621144922423.png"
alt="image-20230621144922423" />
<figcaption aria-hidden="true">image-20230621144922423</figcaption>
</figure>
<h3 id="官方建议">官方建议</h3>
<ol type="1">
<li>不建议使用DP来进行数据并行，因为这不是一个真正的并发执行（python
GIL），并且，由于数据的转移，反而会减慢模型的执行，建议使用DDP。</li>
<li>所有拷贝来的数据都是一次性的，每次迭代后都会销毁重建，所以这些模型上如果有数据修改，将不会持久化。（<strong>Input最后做的gather是为了下一层网络的输入</strong>）</li>
</ol>
<h2 id="参考">参考</h2>
<p><a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html?highlight=data+parallel#torch.nn.DataParallel">Pytorch
DATAPARALLEL</a></p>
<p><a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/extending.html#extending-torch-autograd">Extending
torch.autograd</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/343951042">PyTorch 源码解读之
DP &amp; DDP：模型并行和分布式训练解析</a></p>
<p><a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/187610959">[原创][深度][PyTorch]
DDP系列第二篇：实现原理与源代码解析</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/13/mpi%E5%85%A5%E9%97%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="hipudding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hipudding's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | hipudding's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/13/mpi%E5%85%A5%E9%97%A8/" class="post-title-link" itemprop="url">mpi入门</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-06-13 16:32:00" itemprop="dateCreated datePublished" datetime="2023-06-13T16:32:00+08:00">2023-06-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-06-21 15:59:43" itemprop="dateModified" datetime="2023-06-21T15:59:43+08:00">2023-06-21</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>MPI全称叫做<a
target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%A8%8A%E6%81%AF%E5%82%B3%E9%81%9E%E4%BB%8B%E9%9D%A2">消息传递接口</a>（Message
passing interface）</p>
<h2 id="安装mpi4py">安装mpi4py</h2>
<p>Python可以使用<a
target="_blank" rel="noopener" href="https://github.com/mpi4py/mpi4py">mpi4py库</a>，使用pip安装的话需要提前安装好openmpi库：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libopenmpi-dev</span><br></pre></td></tr></table></figure>
<p>由于Anaconda存在的缘故，pip安装编译会报找不到一些so库。解决方法见<a
target="_blank" rel="noopener" href="https://github.com/mpi4py/mpi4py/issues/343">issue</a></p>
<p>不过既然Anaconda存在，可以直接使用conda安装：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge mpi4py openmpi</span><br></pre></td></tr></table></figure>
<h2 id="名词介绍">名词介绍</h2>
<ul>
<li>world: 一个进程组，聚集通信在这个进程组中进行</li>
<li>rank: 当前进程（自己）的编号，0是master进程</li>
<li>world_size: 进程组中进程的个数</li>
</ul>
<h2 id="点对点通信">点对点通信</h2>
<p><strong>举例</strong></p>
<ul>
<li>send(isend 非阻塞)</li>
<li>recv(irecv 非阻塞)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line">rank = comm.Get_rank()</span><br><span class="line">size = comm.Get_size()</span><br><span class="line"></span><br><span class="line">recv_data = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    matrix = np.random.randint(-<span class="number">9</span>, <span class="number">9</span>, size=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    comm.send(matrix, <span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process &#123;&#125; send matrix &#123;&#125; to other processes&quot;</span>.<span class="built_in">format</span>(rank, matrix))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    matrix_recv = comm.recv()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process &#123;&#125; recv matrix &#123;&#125; from master&quot;</span>.<span class="built_in">format</span>(rank, matrix_recv))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">mpiexec -np 2 python mpi_test.py </span><br><span class="line"></span><br><span class="line">process 1 recv matrix </span><br><span class="line">[[ 0  1 -7  3 -7 -1 -2  2 -3  7]</span><br><span class="line"> [ 2 -6  7  4 -5 -1  0 -4  2  4]</span><br><span class="line"> [ 0  1  3  5  8 -3 -8 -4 -3 -7]</span><br><span class="line"> [ 1 -9 -8  5 -9 -7 -7 -6 -6 -2]</span><br><span class="line"> [-2  3 -3 -4  3  7  0  2  7  8]</span><br><span class="line"> [-3 -6 -4 -5 -5 -1  2 -3 -9  3]</span><br><span class="line"> [-6  6  5  4 -5  8 -2 -2  3  6]</span><br><span class="line"> [ 1  7 -6 -7  0 -2  8  4  7 -6]</span><br><span class="line"> [-2 -7 -5 -4 -9  0 -3  8 -2  7]</span><br><span class="line"> [-3  2  2  6  0 -8 -5  0 -4  5]] from master</span><br><span class="line"> </span><br><span class="line">process 0 send matrix </span><br><span class="line">[[ 0  1 -7  3 -7 -1 -2  2 -3  7]</span><br><span class="line"> [ 2 -6  7  4 -5 -1  0 -4  2  4]</span><br><span class="line"> [ 0  1  3  5  8 -3 -8 -4 -3 -7]</span><br><span class="line"> [ 1 -9 -8  5 -9 -7 -7 -6 -6 -2]</span><br><span class="line"> [-2  3 -3 -4  3  7  0  2  7  8]</span><br><span class="line"> [-3 -6 -4 -5 -5 -1  2 -3 -9  3]</span><br><span class="line"> [-6  6  5  4 -5  8 -2 -2  3  6]</span><br><span class="line"> [ 1  7 -6 -7  0 -2  8  4  7 -6]</span><br><span class="line"> [-2 -7 -5 -4 -9  0 -3  8 -2  7]</span><br><span class="line"> [-3  2  2  6  0 -8 -5  0 -4  5]] to other processes</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="聚集通信">聚集通信</h2>
<p><strong>举例</strong></p>
<ul>
<li><p>bcast</p></li>
<li><p>scatter</p></li>
<li><p>gather(all_gather所有的进程均收到gather结果)</p></li>
<li><p>reduce(all_reduce所有的进程均收到reduce结果)</p></li>
</ul>
<p><strong>bcast</strong>
广播消息到所有进程组内进程，调用者如果是master，则是发送；其他进程是接收</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line">rank = comm.Get_rank()</span><br><span class="line">size = comm.Get_size()</span><br><span class="line"></span><br><span class="line">recv_data = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    matrix = np.random.randint(-<span class="number">9</span>, <span class="number">9</span>, size=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process &#123;&#125; prepare random matrix &#123;&#125;&quot;</span>.<span class="built_in">format</span>(rank, matrix))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    matrix = np.zeros((<span class="number">10</span>, <span class="number">10</span>), dtype=<span class="built_in">int</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process &#123;&#125; use empty matrix &#123;&#125;&quot;</span>.<span class="built_in">format</span>(rank, matrix))</span><br><span class="line">matrix = comm.bcast(matrix)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;process &#123;&#125; bcast matrix &#123;&#125;&quot;</span>.<span class="built_in">format</span>(rank, matrix))</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">process 1 use empty matrix [[0 0 0 0 0 0 0 0 0 0]</span><br><span class="line"> [0 0 0 0 0 0 0 0 0 0]</span><br><span class="line"> [0 0 0 0 0 0 0 0 0 0]</span><br><span class="line"> [0 0 0 0 0 0 0 0 0 0]</span><br><span class="line"> [0 0 0 0 0 0 0 0 0 0]</span><br><span class="line"> [0 0 0 0 0 0 0 0 0 0]</span><br><span class="line"> [0 0 0 0 0 0 0 0 0 0]</span><br><span class="line"> [0 0 0 0 0 0 0 0 0 0]</span><br><span class="line"> [0 0 0 0 0 0 0 0 0 0]</span><br><span class="line"> [0 0 0 0 0 0 0 0 0 0]]</span><br><span class="line"> </span><br><span class="line">process 0 prepare random matrix [[ 5 -8  8  4  1 -7 -8 -6  1  3]</span><br><span class="line"> [-6 -5  6 -1 -8  5  7  2  3  7]</span><br><span class="line"> [-2 -9 -9  7  0  8 -4  2 -8 -1]</span><br><span class="line"> [ 3 -1  3  3 -7  7 -5 -5 -9 -7]</span><br><span class="line"> [ 0 -4 -7 -8 -8 -8  7  2  2  1]</span><br><span class="line"> [-2  0  1  7  6  3  8 -1  1  8]</span><br><span class="line"> [ 6 -4  7 -7  6 -1 -4  6 -6 -9]</span><br><span class="line"> [-3  2  8 -7  8 -8  8  3 -1 -3]</span><br><span class="line"> [ 6  7  2 -2  1 -5  1  2  1 -2]</span><br><span class="line"> [ 2 -3 -2 -3 -7  6  7 -8 -9  4]]</span><br><span class="line"> </span><br><span class="line">process 0 bcast matrix [[ 5 -8  8  4  1 -7 -8 -6  1  3]</span><br><span class="line"> [-6 -5  6 -1 -8  5  7  2  3  7]</span><br><span class="line"> [-2 -9 -9  7  0  8 -4  2 -8 -1]</span><br><span class="line"> [ 3 -1  3  3 -7  7 -5 -5 -9 -7]</span><br><span class="line"> [ 0 -4 -7 -8 -8 -8  7  2  2  1]</span><br><span class="line"> [-2  0  1  7  6  3  8 -1  1  8]</span><br><span class="line"> [ 6 -4  7 -7  6 -1 -4  6 -6 -9]</span><br><span class="line"> [-3  2  8 -7  8 -8  8  3 -1 -3]</span><br><span class="line"> [ 6  7  2 -2  1 -5  1  2  1 -2]</span><br><span class="line"> [ 2 -3 -2 -3 -7  6  7 -8 -9  4]]</span><br><span class="line"> </span><br><span class="line">process 1 bcast matrix [[ 5 -8  8  4  1 -7 -8 -6  1  3]</span><br><span class="line"> [-6 -5  6 -1 -8  5  7  2  3  7]</span><br><span class="line"> [-2 -9 -9  7  0  8 -4  2 -8 -1]</span><br><span class="line"> [ 3 -1  3  3 -7  7 -5 -5 -9 -7]</span><br><span class="line"> [ 0 -4 -7 -8 -8 -8  7  2  2  1]</span><br><span class="line"> [-2  0  1  7  6  3  8 -1  1  8]</span><br><span class="line"> [ 6 -4  7 -7  6 -1 -4  6 -6 -9]</span><br><span class="line"> [-3  2  8 -7  8 -8  8  3 -1 -3]</span><br><span class="line"> [ 6  7  2 -2  1 -5  1  2  1 -2]</span><br><span class="line"> [ 2 -3 -2 -3 -7  6  7 -8 -9  4]]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>scatter</strong>会将发送的数据拆分，然后分给进程组中的进程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line">rank = comm.Get_rank()</span><br><span class="line">size = comm.Get_size()</span><br><span class="line"></span><br><span class="line">recv_data = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    matrix = np.random.randint(-<span class="number">9</span>, <span class="number">9</span>, size=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    line = np.array_split(matrix, <span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process &#123;&#125; prepare random matrix &#123;&#125;&quot;</span>.<span class="built_in">format</span>(rank, matrix))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    line = <span class="literal">None</span></span><br><span class="line">one_piece = comm.scatter(line)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;process &#123;&#125; bcast matrix &#123;&#125;&quot;</span>.<span class="built_in">format</span>(rank, one_piece))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">mpiexec --oversubscribe -np 10 python mpi_test.py</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">数据的分组数量和进程数要对应。 默认mpi最大进程数量和cpu相同，可以添加--oversubscribe解除限制</span></span><br><span class="line"></span><br><span class="line">process 0 prepare random matrix [[-9 -2 -6  4  1  7  5  5 -1 -3]</span><br><span class="line"> [-4  6  3  5 -9 -6  7  3  0 -1]</span><br><span class="line"> [-9 -6  2  5 -1  2 -2 -5 -8 -7]</span><br><span class="line"> [ 3 -4 -1 -9 -2  5  4 -8  0  1]</span><br><span class="line"> [ 3  1 -2  6 -4  0 -2 -3  6  8]</span><br><span class="line"> [ 6  5 -8 -7 -3 -7 -5 -8  5  8]</span><br><span class="line"> [-3 -9  2 -2  0 -7  6 -5  5 -2]</span><br><span class="line"> [-6 -4  8  5 -6  6  2 -3 -2  4]</span><br><span class="line"> [-5  7  3 -2  4 -8  3 -5  7 -5]</span><br><span class="line"> [ 0  4 -9 -1 -5 -2 -1 -5  7  7]]</span><br><span class="line">process 0 bcast matrix [[-9 -2 -6  4  1  7  5  5 -1 -3]]</span><br><span class="line">process 2 bcast matrix [[-9 -6  2  5 -1  2 -2 -5 -8 -7]]</span><br><span class="line">process 4 bcast matrix [[ 3  1 -2  6 -4  0 -2 -3  6  8]]</span><br><span class="line">process 6 bcast matrix [[-3 -9  2 -2  0 -7  6 -5  5 -2]]</span><br><span class="line">process 1 bcast matrix [[-4  6  3  5 -9 -6  7  3  0 -1]]</span><br><span class="line">process 3 bcast matrix [[ 3 -4 -1 -9 -2  5  4 -8  0  1]]</span><br><span class="line">process 5 bcast matrix [[ 6  5 -8 -7 -3 -7 -5 -8  5  8]]</span><br><span class="line">process 8 bcast matrix [[-5  7  3 -2  4 -8  3 -5  7 -5]]</span><br><span class="line">process 9 bcast matrix [[ 0  4 -9 -1 -5 -2 -1 -5  7  7]]</span><br><span class="line">process 7 bcast matrix [[-6 -4  8  5 -6  6  2 -3 -2  4]]</span><br></pre></td></tr></table></figure>
<p><strong>gather</strong>收集所有分发后的数据，比如，我们需要对scatter分发的所有数据+1，然后再收集回来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line">rank = comm.Get_rank()</span><br><span class="line">size = comm.Get_size()</span><br><span class="line"></span><br><span class="line">recv_data = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    matrix = np.random.randint(-<span class="number">9</span>, <span class="number">9</span>, size=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    line = np.array_split(matrix, <span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process &#123;&#125; prepare random matrix &#123;&#125;&quot;</span>.<span class="built_in">format</span>(rank, matrix))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    line = <span class="literal">None</span></span><br><span class="line">line = comm.scatter(line)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> line:</span><br><span class="line">    item += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">recv_result = comm.gather(line)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    matrix = np.vstack(recv_result)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process &#123;&#125; get calculated matrix &#123;&#125;&quot;</span>.<span class="built_in">format</span>(rank, matrix))</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">process 0 prepare random matrix </span><br><span class="line">[[-2  4  0  4 -2 -1  7  3 -1  4]</span><br><span class="line"> [-4 -8 -1 -9  8  7  8 -3 -6  1]</span><br><span class="line"> [ 1 -8  0  6 -6 -8 -7  2 -9 -1]</span><br><span class="line"> [ 7 -7  0 -4 -4  0 -2  4 -7  7]</span><br><span class="line"> [-7  3  0 -8  5 -8 -2  0  7  2]</span><br><span class="line"> [-6 -9 -3 -8  0  0  0 -7 -4 -5]</span><br><span class="line"> [ 2 -6  3 -8  8 -8 -2  0 -2 -9]</span><br><span class="line"> [ 8  8 -8 -8  7  8  4 -3 -9  3]</span><br><span class="line"> [ 8 -4  4  2  8 -2  2  7  0 -6]</span><br><span class="line"> [ 3  1 -3  2 -8 -6 -4 -5  3  0]]</span><br><span class="line"> </span><br><span class="line">process 0 get calculated matrix </span><br><span class="line">[[-1  5  1  5 -1  0  8  4  0  5]</span><br><span class="line"> [-3 -7  0 -8  9  8  9 -2 -5  2]</span><br><span class="line"> [ 2 -7  1  7 -5 -7 -6  3 -8  0]</span><br><span class="line"> [ 8 -6  1 -3 -3  1 -1  5 -6  8]</span><br><span class="line"> [-6  4  1 -7  6 -7 -1  1  8  3]</span><br><span class="line"> [-5 -8 -2 -7  1  1  1 -6 -3 -4]</span><br><span class="line"> [ 3 -5  4 -7  9 -7 -1  1 -1 -8]</span><br><span class="line"> [ 9  9 -7 -7  8  9  5 -2 -8  4]</span><br><span class="line"> [ 9 -3  5  3  9 -1  3  8  1 -5]</span><br><span class="line"> [ 4  2 -2  3 -7 -5 -3 -4  4  1]]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>reduce</strong> 将收集到的数据进行规约，例如SUM，MAX等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">comm = MPI.COMM_WORLD</span><br><span class="line">rank = comm.Get_rank()</span><br><span class="line">size = comm.Get_size()</span><br><span class="line"></span><br><span class="line">recv_data = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    matrix = np.random.randint(-<span class="number">9</span>, <span class="number">9</span>, size=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    line = np.array_split(matrix, <span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process &#123;&#125; prepare random matrix &#123;&#125;&quot;</span>.<span class="built_in">format</span>(rank, matrix))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    line = <span class="literal">None</span></span><br><span class="line">line = comm.scatter(line)</span><br><span class="line">sum_result = comm.reduce(line, op=MPI.SUM)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process &#123;&#125; get calculated sum result &#123;&#125;&quot;</span>.<span class="built_in">format</span>(rank, sum_result))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">process 0 prepare random matrix </span><br><span class="line">[[ 2 -9 -9 -8 -9 -8 -7  8 -6  5]</span><br><span class="line"> [ 0  6  6 -2 -6  4 -5 -7  3 -4]</span><br><span class="line"> [-9  2  6 -5 -1 -6  5 -2  3  4]</span><br><span class="line"> [ 7  4 -6 -5  1  4 -5  5 -1  1]</span><br><span class="line"> [ 1  2 -8 -7  5  2 -6 -4  5 -8]</span><br><span class="line"> [-8  0  7  1  0 -8  3 -8 -2  3]</span><br><span class="line"> [ 6  5  2 -7 -6 -3 -7  4  2 -1]</span><br><span class="line"> [ 2 -8  8 -1 -3 -9  0  4 -9 -9]</span><br><span class="line"> [-4 -7 -1 -8  4  7  1  6  4  5]</span><br><span class="line"> [-2  6  3  3  7  7 -4  1 -7 -3]]</span><br><span class="line"> </span><br><span class="line">process 0 get calculated sum result [[ -5   1   8 -39  -8 -10 -25   7  -8  -7]]</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/12/DeepSpeed-%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="hipudding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hipudding's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | hipudding's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/12/DeepSpeed-%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">DeepSpeed 安装使用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-06-12 16:57:33" itemprop="dateCreated datePublished" datetime="2023-06-12T16:57:33+08:00">2023-06-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-06-19 09:24:00" itemprop="dateModified" datetime="2023-06-19T09:24:00+08:00">2023-06-19</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="deepspeedubuntucpu">DeepSpeed+Ubuntu+CPU</h2>
<p>目前CPU支持很有限，仅支持部分推理。环境配置可参考<a
target="_blank" rel="noopener" href="https://github.com/microsoft/DeepSpeed/commit/1f72082fc0ea159d0de46886d8e713dda7df9ce2#diff-69a0fa9b9a28351868fc14c345088d9af3cf3560538482a386dc616ebc023fe3">CI配置</a></p>
<p><strong>安装intel_extension_for_pytorch</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install intel_extension_for_pytorch</span><br><span class="line">python -m pip install oneccl_bind_pt==2.0 -f https://developer.intel.com/ipex-whl-stable-cpu</span><br></pre></td></tr></table></figure>
<p><strong>安装oneCCL</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/oneapi-src/oneCCL</span><br><span class="line">cd oneCCL</span><br><span class="line">mkdir build</span><br><span class="line">cd build</span><br><span class="line">cmake ..</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">source ./_install/env/setvars.sh</span><br></pre></td></tr></table></figure>
<p><strong>安装Transformers(用于跑用例)</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/huggingface/transformers</span><br><span class="line">cd transformers</span><br><span class="line">git rev-parse --short HEAD</span><br><span class="line">pip install .</span><br></pre></td></tr></table></figure>
<p><strong>安装DeepSpeed</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install DeepSpeed</span><br></pre></td></tr></table></figure>
<p><strong>ds_report</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">--------------------------------------------------</span><br><span class="line">DeepSpeed C++/CUDA extension op report</span><br><span class="line">--------------------------------------------------</span><br><span class="line">NOTE: Ops not installed will be just-in-time (JIT) compiled at</span><br><span class="line">      runtime if needed. Op compatibility means that your system</span><br><span class="line">      meet the required dependencies to JIT install the op.</span><br><span class="line">--------------------------------------------------</span><br><span class="line">JIT compiled ops requires ninja</span><br><span class="line">ninja .................. [OKAY]</span><br><span class="line">--------------------------------------------------</span><br><span class="line">op name ................ installed .. compatible</span><br><span class="line">--------------------------------------------------</span><br><span class="line">deepspeed_not_implemented  [NO] ....... [OKAY]</span><br><span class="line">deepspeed_ccl_comm ....... [NO] ....... [OKAY]</span><br><span class="line">--------------------------------------------------</span><br><span class="line">DeepSpeed general environment info:</span><br><span class="line">torch install path ............... [&#x27;/home/hua/anaconda3/lib/python3.10/site-packages/torch&#x27;]</span><br><span class="line">torch version .................... 2.0.1+cu117</span><br><span class="line">deepspeed install path ........... [&#x27;/home/hua/anaconda3/lib/python3.10/site-packages/deepspeed&#x27;]</span><br><span class="line">deepspeed info ................... 0.9.4+e5fe5f65, e5fe5f65, master</span><br><span class="line">deepspeed wheel compiled w. ...... torch 0.0</span><br></pre></td></tr></table></figure>
<h2 id="deepspeedubuntugpu">DeepSpeed+Ubuntu+GPU</h2>
<p><strong>操作系统</strong></p>
<p>华为云上gpu的镜像是16.04的，很多依赖的软件版本过低，建议升级到20.04，DeepSpeedExample有些需要高版本的glibc，可以直接升级到22.04。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade</span><br><span class="line">sudo apt-get dist-upgrade</span><br><span class="line">sudo do-release-upgrade</span><br></pre></td></tr></table></figure>
<p><strong>GPU驱动和cuda</strong></p>
<ul>
<li><p><a
target="_blank" rel="noopener" href="https://www.nvidia.cn/Download/index.aspx?lang=cn">驱动下载页面</a>选择相应的型号，选择cuda
11.7</p></li>
<li><p><a
target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-11-7-0-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=22.04&amp;target_type=runfile_local">CUDA
toolkit下载页面</a>选择系统版本，然后下载runfile（使用apt总是会升级驱动和cuda到最新版本，所以直接下载二进制安装）。</p></li>
</ul>
<p><strong>pip源</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>
<p><strong>安装<a
target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions/">pytorch</a></strong></p>
<p>DeepSpeed
0.9.2（pip版本）目前依赖的是pytorch1.13.1，安装对应的版本。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117</span><br></pre></td></tr></table></figure>
<p><strong>triton==1.0.0</strong></p>
<p>DeepSpeed依赖triton版本是1.0.0，pip仓库无法直接安装，git上下载源码编译安装。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编译依赖</span></span><br><span class="line">sudo apt-get install llvm-11 llvm-11-*</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">源码安装</span></span><br><span class="line">wget https://github.com/openai/triton/archive/refs/tags/v1.0.zip</span><br><span class="line">unzip v1.0.zip</span><br><span class="line">cd triton/python</span><br><span class="line">pip install cmake</span><br><span class="line">pip install .</span><br></pre></td></tr></table></figure>
<p><strong>安装DeepSpeed</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">预编译算子(编译不通过：https://github.com/microsoft/DeepSpeed/issues/425)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">workground: Setting NVCC_PREPEND_FLAGS=<span class="string">&quot;--forward-unknown-opts&quot;</span></span></span><br><span class="line">DS_BUILD_OPS=1 pip install deepspeed --global-option=&quot;build_ext&quot; --global-option=&quot;-j8&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">JIT_load</span></span><br><span class="line">pip install deepspeed</span><br></pre></td></tr></table></figure>
<p><strong>ds_report</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">--------------------------------------------------</span><br><span class="line">DeepSpeed C++/CUDA extension op report</span><br><span class="line">--------------------------------------------------</span><br><span class="line">NOTE: Ops not installed will be just-in-time (JIT) compiled at</span><br><span class="line">      runtime if needed. Op compatibility means that your system</span><br><span class="line">      meet the required dependencies to JIT install the op.</span><br><span class="line">--------------------------------------------------</span><br><span class="line">JIT compiled ops requires ninja</span><br><span class="line">ninja .................. [OKAY]</span><br><span class="line">--------------------------------------------------</span><br><span class="line">op name ................ installed .. compatible</span><br><span class="line">--------------------------------------------------</span><br><span class="line">async_io ............... [NO] ....... [OKAY]</span><br><span class="line">cpu_adagrad ............ [NO] ....... [OKAY]</span><br><span class="line">cpu_adam ............... [NO] ....... [OKAY]</span><br><span class="line">fused_adam ............. [NO] ....... [OKAY]</span><br><span class="line">fused_lamb ............. [NO] ....... [OKAY]</span><br><span class="line">quantizer .............. [NO] ....... [OKAY]</span><br><span class="line">random_ltd ............. [NO] ....... [OKAY]</span><br><span class="line">sparse_attn ............ [NO] ....... [OKAY]</span><br><span class="line">spatial_inference ...... [NO] ....... [OKAY]</span><br><span class="line">transformer ............ [NO] ....... [OKAY]</span><br><span class="line">stochastic_transformer . [NO] ....... [OKAY]</span><br><span class="line">transformer_inference .. [NO] ....... [OKAY]</span><br><span class="line">utils .................. [NO] ....... [OKAY]</span><br><span class="line">--------------------------------------------------</span><br><span class="line">DeepSpeed general environment info:</span><br><span class="line">torch install path ............... [&#x27;/home/hua/anaconda3/lib/python3.10/site-packages/torch&#x27;]</span><br><span class="line">torch version .................... 1.13.1+cu117</span><br><span class="line">deepspeed install path ........... [&#x27;/home/hua/anaconda3/lib/python3.10/site-packages/deepspeed&#x27;]</span><br><span class="line">deepspeed info ................... 0.9.2, unknown, unknown</span><br><span class="line">torch cuda version ............... 11.7</span><br><span class="line">torch hip version ................ None</span><br><span class="line">nvcc version ..................... 11.7</span><br><span class="line">deepspeed wheel compiled w. ...... torch 1.13, cuda 11.7</span><br></pre></td></tr></table></figure>
<p><strong>运行例子</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/microsoft/DeepSpeedExamples.git</span><br><span class="line">cd DeepSpeedExamples/training/cifar</span><br><span class="line">./run_ds.py</span><br></pre></td></tr></table></figure>
<p>python报错，修改方法：</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">diff --git a/training/cifar/cifar10_deepspeed.py b/training/cifar/cifar10_deepspeed.py</span></span><br><span class="line"><span class="comment">index 33ea569..d1117c3 100755</span></span><br><span class="line"><span class="comment">--- a/training/cifar/cifar10_deepspeed.py</span></span><br><span class="line"><span class="comment">+++ b/training/cifar/cifar10_deepspeed.py</span></span><br><span class="line"><span class="meta">@@ -159,7 +159,7 @@</span> def imshow(img):</span><br><span class="line"></span><br><span class="line"> # get some random training images</span><br><span class="line"> dataiter = iter(trainloader)</span><br><span class="line"><span class="deletion">-images, labels = dataiter.next()</span></span><br><span class="line"><span class="addition">+images, labels = next(dataiter)</span></span><br><span class="line"></span><br><span class="line"> # show images</span><br><span class="line"> imshow(torchvision.utils.make_grid(images))</span><br><span class="line"><span class="meta">@@ -309,7 +309,7 @@</span> print(&#x27;Finished Training&#x27;)</span><br><span class="line"> # Okay, first step. Let us display an image from the test set to get familiar.</span><br><span class="line"></span><br><span class="line"> dataiter = iter(testloader)</span><br><span class="line"><span class="deletion">-images, labels = dataiter.next()</span></span><br><span class="line"><span class="addition">+images, labels = next(dataiter)</span></span><br><span class="line"></span><br><span class="line"> # print images</span><br><span class="line"> imshow(torchvision.utils.make_grid(images))</span><br><span class="line"><span class="comment">diff --git a/training/cifar/cifar10_tutorial.py b/training/cifar/cifar10_tutorial.py</span></span><br><span class="line"><span class="comment">index 2154e36..114e8c5 100644</span></span><br><span class="line"><span class="comment">--- a/training/cifar/cifar10_tutorial.py</span></span><br><span class="line"><span class="comment">+++ b/training/cifar/cifar10_tutorial.py</span></span><br><span class="line"><span class="meta">@@ -110,7 +110,7 @@</span> def imshow(img):</span><br><span class="line"></span><br><span class="line"> # get some random training images</span><br><span class="line"> dataiter = iter(trainloader)</span><br><span class="line"><span class="deletion">-images, labels = dataiter.next()</span></span><br><span class="line"><span class="addition">+images, labels = next(dataiter)</span></span><br><span class="line"></span><br><span class="line"> # show images</span><br><span class="line"> imshow(torchvision.utils.make_grid(images))</span><br><span class="line"><span class="meta">@@ -219,7 +219,7 @@</span> torch.save(net.state_dict(), PATH)</span><br><span class="line"> # Okay, first step. Let us display an image from the test set to get familiar.</span><br><span class="line"></span><br><span class="line"> dataiter = iter(testloader)</span><br><span class="line"><span class="deletion">-images, labels = dataiter.next()</span></span><br><span class="line"><span class="addition">+images, labels = next(dataiter)</span></span><br><span class="line"></span><br><span class="line"> # print images</span><br><span class="line"> imshow(torchvision.utils.make_grid(images))</span><br></pre></td></tr></table></figure>
<h2 id="简单模型改写为deepspeed">简单模型改写为DeepSpeed</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">with_ds = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> with_ds:</span><br><span class="line">    <span class="keyword">import</span> deepspeed</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">x_data = torch.tensor([[<span class="number">1.0</span>], [<span class="number">2.0</span>], [<span class="number">3.0</span>]]).to(device)</span><br><span class="line">y_data = torch.tensor([[<span class="number">2.0</span>], [<span class="number">4.0</span>], [<span class="number">6.0</span>]]).to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearModel</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearModel, self).__init__()</span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">1</span>, <span class="number">1</span>).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y_pred = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = LinearModel()</span><br><span class="line">criterion = torch.nn.MSELoss(size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> with_ds:</span><br><span class="line">    optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    ds_config = &#123;</span><br><span class="line">        <span class="string">&quot;train_micro_batch_size_per_gpu&quot;</span>: <span class="number">2</span>,</span><br><span class="line">        <span class="string">&quot;optimizer&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;SGD&quot;</span>,</span><br><span class="line">            <span class="string">&quot;params&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;lr&quot;</span>: <span class="number">1e-2</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    model, _, _, _ = deepspeed.initialize(model=model, model_parameters=model.parameters(), config=ds_config)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    <span class="built_in">print</span>(epoch, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> with_ds:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model.backward(loss)</span><br><span class="line">        model.step()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w = &#x27;</span>, model.linear.weight.item())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b = &#x27;</span>, model.linear.bias.item())</span><br><span class="line"></span><br><span class="line">x_test = torch.tensor([[<span class="number">4.0</span>]]).to(device)</span><br><span class="line">y_test = model(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y_pred = &#x27;</span>, y_test.data)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>DeepSpeed基本执行流程</strong></p>
<p><em>这个简单的模型实际上还是完全调用的pytorch的函数，ds包的wapper其实啥都没干，完全透传</em></p>
<ol type="1">
<li>首先获取Accelerator（加速器），判断能不能import
intel_extension_for_deepspeed，如果能就用XPU，如果不能就用CUDA（Accelerator将设备管理，内存管理，Tensor等等进行了抽象，不同的后端设备继承实现），高版本这部分逻辑有改变，可以通过环境变量控制。<strong>切入点1，这里需要判断是否能够使用npu</strong></li>
<li>选择并行计算后端，如果Torch.distributed已经初始化，则使用直接使用，检查是否在Aure或者aws机器上，针对这些机器做环境变量配置，否则尝试寻找mpi，然后根据Accelerator的comm
backend类型初始化TorchBackend.<strong>切入点2，这里需要针对华为云机器做专门的环境变量配置，以及支持昇腾并行后端</strong></li>
<li>解析ds的配置文件</li>
<li>创建ds引擎
<ol type="1">
<li>检查环境变量，配置dist相关配置，包括rank，world size 等等</li>
<li>用dist分发模型参数，所有进程同步模型参数</li>
<li>根据配置创建optimizer，例如，上例中，就会生成torch自带的SGD优化器，也可以指定ds提供的Adam，lamb等优化器</li>
<li>配置checkpoint</li>
<li>编译Utils，就是flateen_unflateen.cpp</li>
</ol></li>
<li>执行forward，计算损失
<strong>切入点3，以下基本调用的都是pytorch的optimizer，这些需要pytorch有昇腾支持，另外，DS提供的优化器也需要昇腾支持</strong></li>
<li>反向传播
<ol type="1">
<li>梯度累加</li>
<li>根据是否使用zero优化，自动精度，混合精度等调用optimizer其他wapper的backward，并传入合适的参数</li>
<li>多进程计算梯度并收集结果</li>
</ol></li>
<li>更新参数
<ol type="1">
<li>如果到了梯度累加的预制，根据不同的配置，最终调用optimizer.step更新参数，并清空梯度信息</li>
</ol></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/06/%E5%89%8D%E5%90%91-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="hipudding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hipudding's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | hipudding's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/06/%E5%89%8D%E5%90%91-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99/" class="post-title-link" itemprop="url">前向&反向传播&链式法则</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-06-06 11:23:51 / 修改时间：13:06:25" itemprop="dateCreated datePublished" datetime="2023-06-06T11:23:51+08:00">2023-06-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="神经网络">神经网络</h2>
<p><strong>通俗理解</strong>，神经网络就是给一组输入，经过神经网络的运算后，得到一个在误差范围内的结果。模型的选择和对模型中各个神经元的系数的确定决定了模型的输出结果，为了得到期望的结果，需要有多组输入，和对应的正确结果，用这些数据来训练模型，确定合适的参数组合。参数确定后，即可预测新的输入对应的输出。</p>
<p>举一个简单的例子，两个神经元组成一个一层的神经网络，给定的两个输入，能够得到一个结果。</p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20230601142530229.png"
alt="image-20230601142530229" />
<figcaption aria-hidden="true">image-20230601142530229</figcaption>
</figure>
<h2 id="前向传播">前向传播</h2>
<p><strong>通俗理解</strong>前向传播，就是根据输入计算输出的过程。按上述例子来说，就是
<span class="math display">\[
net_o = i1×w1+b1 + i2×w2+b2
\]</span> 假定输入数据为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">i1 = 0.05, i2 = 0.10;</span><br><span class="line">w1 = 0.15, w2 = 0.20;</span><br><span class="line">b1 = 0.35, b2 = 0.60.</span><br></pre></td></tr></table></figure>
<p>那么： <span class="math display">\[
net_o = i1×w1+b1 + i2×w2+b2 = 0.05×0.15+0.35+0.10*0.20+0.60=0.9775
\]</span> 假定选择sigmoid函数作为激活函数，那么 <span
class="math display">\[
out_o =
\frac{1}{1+\epsilon^{net_o}}=\frac{1}{1+\epsilon^{0.9775}}=0.2734
\]</span></p>
<p>如果此时我们期望的输出为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">o=0.01</span><br></pre></td></tr></table></figure>
<p>误差为 <span class="math display">\[
o-out_o=0.01-0.2734=-0.2634
\]</span></p>
<h2 id="梯度下降法">梯度下降法</h2>
<p>考虑一个抛物线函数： <span class="math display">\[
y=f(x)^2
\]</span></p>
<figure>
<img
src="https://raw.githubusercontent.com/hipudding/blog_img/main/img/image-20230601151845547.png"
alt="image-20230601151845547" />
<figcaption aria-hidden="true">image-20230601151845547</figcaption>
</figure>
<p>X轴为权值，Y轴为误差，那么我们能计算得到曲线斜率为0的位置为最低位置（x=0），如果是一个复杂的多维函数，不容易直接通过计算得出曲线或者平面的最低位置，所以可以使用梯度下降法来通过迭代计算最低位置。相当于放一个小球，小球会在重力的影响下，沿最陡的方向下降。</p>
<p>假设目前在x=10的点上(x0)，梯度为： <span class="math display">\[
\nabla f(x_0)=f&#39;(x0)=2x=20
\]</span>
那梯度的反方向就是下降率最快的方向，如果步长为η=0.2，那么新的位置x1为：
<span class="math display">\[
x_1 = x_0 - \eta×\nabla f(x_0)=10-0.2*20=6
\]</span> 然后继续迭代，直到梯度曲线趋近于0.</p>
<table>
<colgroup>
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>x0</th>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>x4</th>
<th>x5</th>
<th>x6</th>
<th>X7</th>
<th>x8</th>
<th>x9</th>
<th>X10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>梯度</td>
<td>20</td>
<td>12</td>
<td>7,2</td>
<td>4.32</td>
<td>2.59</td>
<td>1.56</td>
<td>0.93</td>
<td>0.56</td>
<td>0.34</td>
<td>0.2</td>
<td>0.12</td>
</tr>
</tbody>
</table>
<p>注意步长的选择，如果步长太小，那么经过多次迭代仍然无法达到曲线或者平面的最低点，如果步长过长，那么或跳过最低点，从而不收敛。</p>
<p>同理，可以从二维（一元函数，曲线）推广到三维（二元函数，平面）甚至多维，目标就是找到最陡的反向，然后按步长走到下一个位置，然后一直迭代下去。</p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/305638940">参考文档</a></p>
<h2 id="反向传播">反向传播</h2>
<p>假设使用均方误差（MSE）来作为误差评估方法，那么误差为(这个是MSE么???)：
<span class="math display">\[
E=\Sigma\frac{1}{2}(o-out_o)^2
\]</span> 由于这个例子中只有一个输出，那么误差为： <span
class="math display">\[
E=\frac{1}{2}(0.01-0.2734)^2=0.03468978
\]</span>
反向传播就是通过误差来计算当前参数的梯度，然后沿梯度下降的方向走一个步长η，迭代此过程。</p>
<p>根据正向传播的函数，能够得到： <span class="math display">\[
out_o = \frac{1}{1+\epsilon^{net_o}} = \frac{1}{1+\epsilon^{(i1×w1+b1 +
i2×w2+b2)}}
\]</span></p>
<p><span class="math display">\[
E=\Sigma\frac{1}{2}(o-out_o)^2=\Sigma\frac{1}{2}(o-\frac{1}{1+\epsilon^{(i1×w1+b1
+ i2×w2+b2)}})^2
\]</span></p>
<p>我们要计算梯度，也就是要计算总的误差E在w1和w2的偏导值。</p>
<p>这个公式比较复杂，所以要使用到求导的链式法则。</p>
<h2 id="链式法则">链式法则</h2>
<p><span class="math display">\[
\frac{\partial E}{\partial w1}=\frac{\partial E}{\partial
out_o}×\frac{\partial out_o}{\partial net_o}×\frac{\partial
net_o}{\partial w1}
\]</span></p>
<p>那么，上述复杂函数的求导就可以转换成几个简单函数求导的乘积。 <span
class="math display">\[
\frac{\partial E}{\partial
out_0}=2×\frac{1}{2}(o-out_o)^1*-1+0=(0.01-0.2734)*-1=0.2634
\]</span></p>
<p><span class="math display">\[
\frac{\partial out_o}{\partial
net_o}=out_o(1-out_o)=0.2734(1-0.2734)=0.19865244
\]</span></p>
<p><span class="math display">\[
\frac{\partial net_o}{\partial w1}=i1=0.05
\]</span></p>
<p>相乘可得： <span class="math display">\[
\frac{\partial E}{\partial w1}=0.2634×0.19865244×0.05=0.0002616
\]</span> 同理： <span class="math display">\[
\frac{\partial E}{\partial w2}=0.2634×0.19865244×0.10=0.0052325
\]</span> 如果步长η=0.2，那么： <span class="math display">\[
w1&#39; = w1 - \eta×\frac{\partial E}{\partial w1} =0.004994768
\]</span></p>
<p><span class="math display">\[
w2&#39; = w2 - \eta×\frac{\partial E}{\partial w2} =0.0989535
\]</span></p>
<p>然后，使用更新后的权值做下一步迭代。</p>
<p><a
target="_blank" rel="noopener" href="https://www.cnblogs.com/charlotte77/p/5629865.html">参考文档</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/06/Python-C-API-pybind11/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="hipudding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hipudding's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | hipudding's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/06/Python-C-API-pybind11/" class="post-title-link" itemprop="url">Python C API && pybind11</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-06-06 11:21:33 / 修改时间：11:22:43" itemprop="dateCreated datePublished" datetime="2023-06-06T11:21:33+08:00">2023-06-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="python-c-api">Python C API</h2>
<h3 id="什么是python的c语言扩展">什么是Python的C语言扩展</h3>
<p><strong>为什么要使用C API</strong> ？</p>
<ul>
<li>C语言实现的复杂计算效率高；</li>
<li>已经有成熟的C语言编写的函数库；</li>
<li>和操作系统相关的操作只能使用C语言实现。</li>
</ul>
<p><strong>为什么Python能够使用C模块</strong> ？</p>
<ul>
<li>cpython虚拟机是由C语言编写；</li>
<li>使用动态链接库的方式可以直接调用模块函数。</li>
</ul>
<p><strong>Python调用C模块都有哪些方法</strong> ？</p>
<ul>
<li>C api；</li>
<li>pybind11；</li>
<li>ctypes；</li>
<li>SWIG；</li>
<li>Cython。</li>
</ul>
<h3 id="我理解的c模块调用原理">我理解的C模块调用原理</h3>
<p><strong>模块加载</strong></p>
<p>python interpreter</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">  Module</span><br><span class="line">    |</span><br><span class="line">   \/                       +-----------+</span><br><span class="line">Load lib(libsum.so) ------&gt; |PyModuleDef|</span><br><span class="line">                            +-----------+          +-----------+</span><br><span class="line">                            |PyMethodDef|  ------&gt; |PyMethodDef|</span><br><span class="line">                            +-----------+          +-----------+</span><br><span class="line">                                                   |C function | ------&gt; sum(c function)</span><br><span class="line">                                                   +-----------+</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>模块内函数调用</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">python --   call python function</span><br><span class="line">              |</span><br><span class="line">              \/</span><br><span class="line">       --  PyArg_ParseTuple</span><br><span class="line">       |      |</span><br><span class="line">       |      \/</span><br><span class="line"> C     |  call c module&#x27;s function</span><br><span class="line">       |      |</span><br><span class="line">       |      \/</span><br><span class="line">       --  Py_BuildValue</span><br><span class="line">              |</span><br><span class="line">              \/</span><br><span class="line"> python -- python function return</span><br><span class="line">       </span><br></pre></td></tr></table></figure>
<h3 id="简单示例">简单示例</h3>
<p><strong>libsum.cc</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;Python.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 实际业务函数体</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">sum</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *   业务函数的包装函数，该函数注册到PyMethodDef中，供Python虚拟机调用</span></span><br><span class="line"><span class="comment"> *   传入两个参数，self和args，args中的参数需要从对象中解析出来。</span></span><br><span class="line"><span class="comment"> *   PyArg_ParseTuple接收一个格式串，根据格式传将参数从PyObject中解析出来</span></span><br><span class="line"><span class="comment"> *   返回一个整数，需要包装成PyObject类型。</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="function"><span class="type">static</span> PyObject* <span class="title">sum_wrapper</span><span class="params">(PyObject* self, PyObject* args)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> a, b;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">PyArg_ParseTuple</span>(args, <span class="string">&quot;ii&quot;</span>, &amp;a, &amp;b)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> result = <span class="built_in">sum</span>(a, b);</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Py_BuildValue</span>(<span class="string">&quot;i&quot;</span>, result);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *   描述需要注册到模块中的函数，每个函数定义一行，以&#123;NULL, NULL, 0, NULL&#125;结束</span></span><br><span class="line"><span class="comment"> *   每行结构有4个参数，分别为：python调用的函数名，实际调用的包装函数；传入参数的类型；</span></span><br><span class="line"><span class="comment"> *                          函数的描述。</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="type">static</span> PyMethodDef SumMethods[] = &#123;</span><br><span class="line">    &#123;<span class="string">&quot;sum&quot;</span>, sum_wrapper, METH_VARARGS, <span class="string">&quot;Calculate the sum of two integers.&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="number">0</span>, <span class="literal">NULL</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *   描述模块属性，参数分别为：固定参数；模块名，就是import后的名字；模块描述；？？？；</span></span><br><span class="line"><span class="comment"> *                         函数数组。</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">struct</span> <span class="title class_">PyModuleDef</span> summodule = &#123;</span><br><span class="line">    PyModuleDef_HEAD_INIT,</span><br><span class="line">    <span class="string">&quot;libsum&quot;</span>,</span><br><span class="line">    <span class="string">&quot;A module that adds two numbers&quot;</span>,</span><br><span class="line">    <span class="number">-1</span>,</span><br><span class="line">    SumMethods</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化模块，以PyInit_模块名 命名</span></span><br><span class="line"><span class="function">PyMODINIT_FUNC <span class="title">PyInit_libsum</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">PyModule_Create</span>(&amp;summodule);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>py_sum.py</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> libsum</span><br><span class="line"></span><br><span class="line">a = <span class="number">1</span></span><br><span class="line">b = <span class="number">2</span></span><br><span class="line">c = libsum.<span class="built_in">sum</span>(a, b)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;a&#125;</span> + <span class="subst">&#123;b&#125;</span> = <span class="subst">&#123;c&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>setup.py</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> distutils.core <span class="keyword">import</span> setup, Extension</span><br><span class="line"></span><br><span class="line">libsum_module = Extension(<span class="string">&#x27;libsum&#x27;</span>,</span><br><span class="line">                    sources = [<span class="string">&#x27;libsum.cc&#x27;</span>],</span><br><span class="line">                    extra_compile_args=[<span class="string">&#x27;-g&#x27;</span>])</span><br><span class="line"></span><br><span class="line">setup (name = <span class="string">&#x27;libsum&#x27;</span>,</span><br><span class="line">       version = <span class="string">&#x27;1.0&#x27;</span>,</span><br><span class="line">       description = <span class="string">&#x27;This is a libsum module&#x27;</span>,</span><br><span class="line">       ext_modules = [libsum_module])</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python setup.py build_ext --inplace</span><br><span class="line"></span><br><span class="line">生成</span><br><span class="line">libsum.cpython-310-x86_64-linux-gnu.so</span><br><span class="line"></span><br><span class="line">可以直接被python import进来</span><br></pre></td></tr></table></figure>
<h3 id="数组和自定义类型">数组和自定义类型</h3>
<p><strong>数组</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">double</span> <span class="title">avg</span><span class="params">(<span class="type">double</span> *arr, <span class="type">size_t</span> len)</span> </span>&#123;</span><br><span class="line">    <span class="type">double</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">        sum += arr[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (sum/len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> PyObject *<span class="title">avg_wrapper</span><span class="params">(PyObject *self, PyObject *args)</span> </span>&#123;</span><br><span class="line">  PyObject *bufobj;</span><br><span class="line">  Py_buffer view;</span><br><span class="line">  <span class="type">double</span> result;</span><br><span class="line">  <span class="keyword">if</span> (!<span class="built_in">PyArg_ParseTuple</span>(args, <span class="string">&quot;O&quot;</span>, &amp;bufobj)) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 数组内存是连续的</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">PyObject_GetBuffer</span>(bufobj, &amp;view,</span><br><span class="line">      PyBUF_ANY_CONTIGUOUS | PyBUF_FORMAT) == <span class="number">-1</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 判断是一维数组</span></span><br><span class="line">  <span class="keyword">if</span> (view.ndim != <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="built_in">PyErr_SetString</span>(PyExc_TypeError, <span class="string">&quot;Expected a 1-dimensional array&quot;</span>);</span><br><span class="line">    <span class="built_in">PyBuffer_Release</span>(&amp;view);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 检查是否是double类型的数组</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">strcmp</span>(view.format,<span class="string">&quot;d&quot;</span>) != <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="built_in">PyErr_SetString</span>(PyExc_TypeError, <span class="string">&quot;Expected an array of doubles&quot;</span>);</span><br><span class="line">    <span class="built_in">PyBuffer_Release</span>(&amp;view);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// View.buf是double数组的首指针，view.shape[0]是这一维度的长度</span></span><br><span class="line">  result = <span class="built_in">avg</span>((<span class="type">double</span>*)view.buf, view.shape[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 需要显式释放Py_buffer</span></span><br><span class="line">  <span class="built_in">PyBuffer_Release</span>(&amp;view);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Py_BuildValue</span>(<span class="string">&quot;d&quot;</span>, result);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>自定义类型</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义C++类型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DoubleWarpper</span> &#123;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">double</span> m_value;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">DoubleWarpper</span>(<span class="type">double</span> value) : <span class="built_in">m_value</span>(value) &#123;&#125;</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">DoubleWarpper</span>() &#123; m_value = <span class="number">0</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">double</span> <span class="title">get</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> m_value; &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">set</span><span class="params">(<span class="type">double</span> value)</span> </span>&#123; m_value = value; &#125;</span><br><span class="line"></span><br><span class="line">  DoubleWarpper <span class="keyword">operator</span>+(<span class="type">const</span> DoubleWarpper &amp;other) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">DoubleWarpper</span>(m_value + other.m_value);</span><br><span class="line">  &#125;</span><br><span class="line">  DoubleWarpper <span class="keyword">operator</span>-(<span class="type">const</span> DoubleWarpper &amp;other) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">DoubleWarpper</span>(m_value - other.m_value);</span><br><span class="line">  &#125;</span><br><span class="line">  DoubleWarpper <span class="keyword">operator</span>*(<span class="type">const</span> DoubleWarpper &amp;other) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">DoubleWarpper</span>(m_value * other.m_value);</span><br><span class="line">  &#125;</span><br><span class="line">  DoubleWarpper <span class="keyword">operator</span>/(<span class="type">const</span> DoubleWarpper &amp;other) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">DoubleWarpper</span>(m_value / other.m_value);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 包装成Python C API需要的结构</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123;</span><br><span class="line">  PyObject_HEAD;</span><br><span class="line">  DoubleWarpper *warpper = <span class="literal">nullptr</span>;</span><br><span class="line">&#125; PyDoubleWarpper;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Python对象构造时调用，需要返回一个PyDoubleWarpper类型的对象。 kwds？？？</span></span><br><span class="line"><span class="function"><span class="type">static</span> PyObject *<span class="title">pycal_new</span><span class="params">(PyTypeObject *type, PyObject *args, PyObject *kwds)</span> </span>&#123;</span><br><span class="line">  PyDoubleWarpper *self;</span><br><span class="line">  self = (PyDoubleWarpper *)type-&gt;<span class="built_in">tp_alloc</span>(type, <span class="number">0</span>);</span><br><span class="line">  <span class="type">char</span> *kwlist[] = &#123;<span class="string">&quot;value&quot;</span>, <span class="number">0</span>&#125;;</span><br><span class="line">  <span class="type">double</span> value = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (!<span class="built_in">PyArg_ParseTupleAndKeywords</span>(args, kwds, <span class="string">&quot;d&quot;</span>, kwlist, &amp;value)) &#123;</span><br><span class="line">    <span class="built_in">Py_DECREF</span>(self);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  self-&gt;warpper = <span class="keyword">new</span> <span class="built_in">DoubleWarpper</span>(value);</span><br><span class="line">  <span class="keyword">return</span> (PyObject *)self;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Python对象销毁时调用</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> *<span class="title">pycal_dealloc</span><span class="params">(PyObject *py_cal)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">delete</span> ((PyDoubleWarpper *)py_cal)-&gt;warpper;</span><br><span class="line">  <span class="built_in">Py_TYPE</span>(py_cal)-&gt;<span class="built_in">tp_free</span>(py_cal);</span><br><span class="line">  <span class="keyword">return</span> (<span class="type">void</span> *)<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从PyObject中获取Calculator指针</span></span><br><span class="line"><span class="function"><span class="type">static</span> DoubleWarpper *<span class="title">get_cal</span><span class="params">(PyObject *obj)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> ((PyDoubleWarpper *)obj)-&gt;warpper;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过Calculator指针构造PyObject</span></span><br><span class="line"><span class="function"><span class="type">static</span> PyObject *<span class="title">return_cal</span><span class="params">(DoubleWarpper *cal, PyTypeObject *type)</span> </span>&#123;</span><br><span class="line">  PyDoubleWarpper *obj = <span class="built_in">PyObject_NEW</span>(PyDoubleWarpper, type);</span><br><span class="line">  obj-&gt;warpper = cal;</span><br><span class="line">  <span class="keyword">return</span> (PyObject *)obj;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Calculator类提供的函数的包装</span></span><br><span class="line"><span class="function"><span class="type">static</span> PyObject *<span class="title">pycal_set</span><span class="params">(PyObject *self, PyObject *args)</span> </span>&#123;</span><br><span class="line">  DoubleWarpper *cal = <span class="built_in">get_cal</span>(self);</span><br><span class="line">  <span class="type">double</span> value = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (!<span class="built_in">PyArg_ParseTuple</span>(args, <span class="string">&quot;d&quot;</span>, &amp;value)) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  cal-&gt;<span class="built_in">set</span>(value);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Py_BuildValue</span>(<span class="string">&quot;i&quot;</span>, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印对象</span></span><br><span class="line"><span class="function"><span class="type">static</span> PyObject *<span class="title">pycal_str</span><span class="params">(PyObject *self)</span> </span>&#123;</span><br><span class="line">  DoubleWarpper *cal = <span class="built_in">get_cal</span>(self);</span><br><span class="line">  std::stringstream ss;</span><br><span class="line">  ss&lt;&lt;cal-&gt;<span class="built_in">get</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Py_BuildValue</span>(<span class="string">&quot;s&quot;</span>, ss.<span class="built_in">str</span>().<span class="built_in">c_str</span>());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现加减乘除</span></span><br><span class="line"><span class="function"><span class="type">static</span> PyObject *<span class="title">pycal_add</span><span class="params">(PyObject *a, PyObject *b)</span> </span>&#123;</span><br><span class="line">  DoubleWarpper *cal_a = <span class="built_in">get_cal</span>(a);</span><br><span class="line">  DoubleWarpper *cal_b = <span class="built_in">get_cal</span>(b);</span><br><span class="line">  DoubleWarpper *ret = <span class="keyword">new</span> <span class="built_in">DoubleWarpper</span>(*cal_a + *cal_b);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">return_cal</span>(ret, a-&gt;ob_type);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> PyObject *<span class="title">pycal_minus</span><span class="params">(PyObject *a, PyObject *b)</span> </span>&#123;</span><br><span class="line">  DoubleWarpper *cal_a = <span class="built_in">get_cal</span>(a);</span><br><span class="line">  DoubleWarpper *cal_b = <span class="built_in">get_cal</span>(b);</span><br><span class="line">  DoubleWarpper *ret = <span class="keyword">new</span> <span class="built_in">DoubleWarpper</span>(*cal_a - *cal_b);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">return_cal</span>(ret, a-&gt;ob_type);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> PyObject *<span class="title">pycal_multipy</span><span class="params">(PyObject *a, PyObject *b)</span> </span>&#123;</span><br><span class="line">  DoubleWarpper *cal_a = <span class="built_in">get_cal</span>(a);</span><br><span class="line">  DoubleWarpper *cal_b = <span class="built_in">get_cal</span>(b);</span><br><span class="line">  DoubleWarpper *ret = <span class="keyword">new</span> <span class="built_in">DoubleWarpper</span>(*cal_a * *cal_b);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">return_cal</span>(ret, a-&gt;ob_type);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> PyObject *<span class="title">pycal_divide</span><span class="params">(PyObject *a, PyObject *b)</span> </span>&#123;</span><br><span class="line">  DoubleWarpper *cal_a = <span class="built_in">get_cal</span>(a);</span><br><span class="line">  DoubleWarpper *cal_b = <span class="built_in">get_cal</span>(b);</span><br><span class="line">  DoubleWarpper *ret = <span class="keyword">new</span> <span class="built_in">DoubleWarpper</span>(*cal_a / *cal_b);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">return_cal</span>(ret, a-&gt;ob_type);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对象的数字属性，这里仅实现了加减乘除</span></span><br><span class="line"><span class="type">static</span> PyNumberMethods numberMethods = &#123;</span><br><span class="line">    pycal_add,      <span class="comment">// nb_add</span></span><br><span class="line">    pycal_minus,    <span class="comment">// nb_subtract;</span></span><br><span class="line">    pycal_multipy,  <span class="comment">// nb_multiply</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_remainder;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_divmod;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_power;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_negative;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_positive;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_absolute;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_bool;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_invert;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_lshift;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_rshift;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_and;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_xor;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_or;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_int;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_reserved;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_float;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_add;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_subtract;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_multiply;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_remainder;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_power;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_lshift;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_rshift;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_and;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_xor;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_or;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_floor_divide;</span></span><br><span class="line">    pycal_divide,   <span class="comment">// nb_true_divide;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_floor_divide;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_inplace_true_divide;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_index;</span></span><br><span class="line">    <span class="literal">nullptr</span>,        <span class="comment">// nb_matrix_multiply;</span></span><br><span class="line">    <span class="literal">nullptr</span>         <span class="comment">// nb_inplace_matrix_multiply;</span></span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// PyCalculator对象的成员函数</span></span><br><span class="line"><span class="type">static</span> PyMethodDef pycal_methods[] = &#123;</span><br><span class="line">    &#123;<span class="string">&quot;set&quot;</span>, (PyCFunction)pycal_set, METH_VARARGS, <span class="string">&quot;set DoubleWarpper value.&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="literal">nullptr</span>&#125;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// PyCalculator对象内容</span></span><br><span class="line"><span class="type">static</span> PyTypeObject DoubleWarpperType = &#123;</span><br><span class="line">    <span class="built_in">PyVarObject_HEAD_INIT</span>(<span class="literal">nullptr</span>, <span class="number">0</span>) <span class="string">&quot;libsum.DoubleWarpper&quot;</span>, <span class="comment">/* tp_name */</span></span><br><span class="line">    <span class="built_in">sizeof</span>(PyDoubleWarpper),                                  <span class="comment">/* tp_basicsize */</span></span><br><span class="line">    <span class="number">0</span>,                                                        <span class="comment">/* tp_itemsize */</span></span><br><span class="line">    (destructor)pycal_dealloc,                                <span class="comment">/* tp_dealloc */</span></span><br><span class="line">    <span class="number">0</span>,                                        <span class="comment">/* tp_vectorcall_offset */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_getattr */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_setattr */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_reserved */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_repr */</span></span><br><span class="line">    &amp;numberMethods,                           <span class="comment">/* tp_as_number */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_as_sequence */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_as_mapping */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_hash  */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_call */</span></span><br><span class="line">    pycal_str,                                <span class="comment">/* tp_str */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_getattro */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_setattro */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_as_buffer */</span></span><br><span class="line">    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE, <span class="comment">/* tp_flags */</span></span><br><span class="line">    <span class="string">&quot;Coustom DoubleWarpper class.&quot;</span>,           <span class="comment">/* tp_doc */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_traverse */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_clear */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_richcompare */</span></span><br><span class="line">    <span class="number">0</span>,                                        <span class="comment">/* tp_weaklistoffset */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_iter */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_iternext */</span></span><br><span class="line">    pycal_methods,                            <span class="comment">/* tp_methods */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_members */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_getset */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_base */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_dict */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_descr_get */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_descr_set */</span></span><br><span class="line">    <span class="number">0</span>,                                        <span class="comment">/* tp_dictoffset */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_init */</span></span><br><span class="line">    <span class="literal">nullptr</span>,                                  <span class="comment">/* tp_alloc */</span></span><br><span class="line">    pycal_new                                 <span class="comment">/* tp_new */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">PyMODINIT_FUNC <span class="title">PyInit_libsum</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">PyType_Ready</span>(&amp;DoubleWarpperType) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  PyObject *<span class="keyword">module</span> = <span class="built_in">PyModule_Create</span>(&amp;summodule);</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">module</span> == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 注册对象，这里为啥要引用+1？？</span></span><br><span class="line">  <span class="built_in">Py_INCREF</span>(&amp;DoubleWarpperType);</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">PyModule_AddObject</span>(<span class="keyword">module</span>, <span class="string">&quot;DoubleWarpper&quot;</span>,</span><br><span class="line">                         (PyObject *)&amp;DoubleWarpperType) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="built_in">Py_DECREF</span>(&amp;DoubleWarpperType);</span><br><span class="line">    <span class="built_in">Py_DECREF</span>(<span class="keyword">module</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">module</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>执行结果</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> array</span><br><span class="line"><span class="keyword">import</span> libsum</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Simple case:&quot;</span>)</span><br><span class="line">a = <span class="number">1</span></span><br><span class="line">b = <span class="number">2</span></span><br><span class="line">c = libsum.<span class="built_in">sum</span>(a, b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;a&#125;</span> + <span class="subst">&#123;b&#125;</span> = <span class="subst">&#123;c&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Pass array:&quot;</span>)</span><br><span class="line">d = libsum.avg(array.array(<span class="string">&#x27;d&#x27;</span>,[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;avg = <span class="subst">&#123;d&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Define new struct:&quot;</span>)</span><br><span class="line">e = libsum.DoubleWarpper(<span class="number">1</span>);</span><br><span class="line">f = libsum.DoubleWarpper(<span class="number">2</span>);</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;e = <span class="subst">&#123;e&#125;</span>, f = <span class="subst">&#123;f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">e.<span class="built_in">set</span>(<span class="number">20</span>);</span><br><span class="line">f.<span class="built_in">set</span>(<span class="number">10</span>);</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;after set: e = <span class="subst">&#123;e&#125;</span>, f = <span class="subst">&#123;f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">g = e+f;</span><br><span class="line">h = e-f;</span><br><span class="line">i = e*f;</span><br><span class="line">j = e/f;</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;<span class="subst">&#123;e&#125;</span> + <span class="subst">&#123;f&#125;</span> = <span class="subst">&#123;g&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;<span class="subst">&#123;e&#125;</span> - <span class="subst">&#123;f&#125;</span> = <span class="subst">&#123;h&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;<span class="subst">&#123;e&#125;</span> * <span class="subst">&#123;f&#125;</span> = <span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;<span class="subst">&#123;e&#125;</span> / <span class="subst">&#123;f&#125;</span> = <span class="subst">&#123;j&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">(base) hua@hfc-ascend:~/code/share$ python py_sum.py</span><br><span class="line">Simple <span class="keyword">case</span>:</span><br><span class="line"><span class="number">1</span> + <span class="number">2</span> = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">Pass array:</span><br><span class="line">avg = <span class="number">3.0</span></span><br><span class="line"></span><br><span class="line">Define new struct:</span><br><span class="line">e = <span class="number">1</span>, f = <span class="number">2</span></span><br><span class="line">after <span class="built_in">set</span>: e = <span class="number">20</span>, f = <span class="number">10</span></span><br><span class="line"><span class="number">20</span> + <span class="number">10</span> = <span class="number">30</span></span><br><span class="line"><span class="number">20</span> - <span class="number">10</span> = <span class="number">10</span></span><br><span class="line"><span class="number">20</span> * <span class="number">10</span> = <span class="number">200</span></span><br><span class="line"><span class="number">20</span> / <span class="number">10</span> = <span class="number">2</span></span><br></pre></td></tr></table></figure>
<h2 id="pybind-11">pybind 11</h2>
<h3 id="简单例子">简单例子</h3>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;Python.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pybind11/pybind11.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pybind11/stl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> py = pybind11;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">sum</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> </span>&#123; <span class="keyword">return</span> a + b; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">avg</span><span class="params">(std::vector&lt;<span class="type">double</span>&gt; &amp;arr)</span> </span>&#123;</span><br><span class="line">  <span class="type">double</span> sum = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> it = arr.<span class="built_in">begin</span>(); it != arr.<span class="built_in">end</span>(); it++) &#123;</span><br><span class="line">    sum += (*it);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> (sum / arr.<span class="built_in">size</span>());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(libsum, m) &#123;</span><br><span class="line">    m.<span class="built_in">doc</span>() = <span class="string">&quot;Py module example.&quot;</span>;</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">&quot;sum&quot;</span>, &amp;sum, <span class="string">&quot;Calculate the sum of two integers.&quot;</span>);</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">&quot;avg&quot;</span>, &amp;avg, <span class="string">&quot;alculate the avg of a double array.&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="自定义类型">自定义类型</h3>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DoubleWarpper</span> &#123;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">double</span> m_value;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">DoubleWarpper</span>(<span class="type">double</span> value) : <span class="built_in">m_value</span>(value) &#123;&#125;</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">DoubleWarpper</span>() &#123; m_value = <span class="number">0</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">double</span> <span class="title">get</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> m_value; &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">set</span><span class="params">(<span class="type">double</span> value)</span> </span>&#123; m_value = value; &#125;</span><br><span class="line">  DoubleWarpper <span class="keyword">operator</span>+(<span class="type">const</span> DoubleWarpper &amp;other) <span class="type">const</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">DoubleWarpper</span>(m_value + other.m_value);</span><br><span class="line">  &#125;</span><br><span class="line">  DoubleWarpper <span class="keyword">operator</span>-(<span class="type">const</span> DoubleWarpper &amp;other) <span class="type">const</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">DoubleWarpper</span>(m_value - other.m_value);</span><br><span class="line">  &#125;</span><br><span class="line">  DoubleWarpper <span class="keyword">operator</span>*(<span class="type">const</span> DoubleWarpper &amp;other) <span class="type">const</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">DoubleWarpper</span>(m_value * other.m_value);</span><br><span class="line">  &#125;</span><br><span class="line">  DoubleWarpper <span class="keyword">operator</span>/(<span class="type">const</span> DoubleWarpper &amp;other) <span class="type">const</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">DoubleWarpper</span>(m_value / other.m_value);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(libsum, m) &#123;</span><br><span class="line">    m.<span class="built_in">doc</span>() = <span class="string">&quot;Py module example.&quot;</span>;</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">&quot;sum&quot;</span>, &amp;sum, <span class="string">&quot;Calculate the sum of two integers.&quot;</span>);</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">&quot;avg&quot;</span>, &amp;avg, <span class="string">&quot;alculate the avg of a double array.&quot;</span>);</span><br><span class="line"></span><br><span class="line">    py::<span class="built_in">class_</span>&lt;DoubleWarpper&gt;(m, <span class="string">&quot;DoubleWarpper&quot;</span>)</span><br><span class="line">      .<span class="built_in">def</span>(py::<span class="built_in">init</span>&lt;<span class="type">double</span>&gt;())</span><br><span class="line">      .<span class="built_in">def</span>(<span class="string">&quot;set&quot;</span>, &amp;DoubleWarpper::set)</span><br><span class="line">      .<span class="built_in">def</span>(<span class="string">&quot;get&quot;</span>, &amp;DoubleWarpper::get)</span><br><span class="line">      <span class="comment">//运算符重载</span></span><br><span class="line">      .<span class="built_in">def</span>(py::self + py::self)</span><br><span class="line">      .<span class="built_in">def</span>(py::self - py::self)</span><br><span class="line">      .<span class="built_in">def</span>(py::self * py::self)</span><br><span class="line">      .<span class="built_in">def</span>(py::self / py::self)</span><br><span class="line">      .<span class="built_in">def</span>(<span class="string">&quot;__repr__&quot;</span>,</span><br><span class="line">          [](DoubleWarpper &amp;warpper) &#123;</span><br><span class="line">            std::stringstream ss;</span><br><span class="line">            ss&lt;&lt;warpper.<span class="built_in">get</span>();</span><br><span class="line">            <span class="keyword">return</span> ss.<span class="built_in">str</span>().<span class="built_in">c_str</span>();</span><br><span class="line">          &#125;</span><br><span class="line">      );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="toml">toml</h2>
<p><strong>pyproject.toml</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pyproject.toml</span></span><br><span class="line">[build-system]</span><br><span class="line">requires = [<span class="string">&quot;setuptools&gt;=61.0&quot;</span>, <span class="string">&quot;cython&quot;</span>]</span><br><span class="line">build-backend = <span class="string">&quot;setuptools.build_meta&quot;</span></span><br><span class="line"></span><br><span class="line">[project]</span><br><span class="line">name        = <span class="string">&quot;libsum&quot;</span></span><br><span class="line">description = <span class="string">&quot;This is a libsum module&quot;</span></span><br><span class="line">version     = <span class="string">&quot;0.0.1&quot;</span></span><br><span class="line">readme      = <span class="string">&quot;README.md&quot;</span></span><br><span class="line">requires-python = <span class="string">&quot;&gt;=3.10&quot;</span></span><br><span class="line">authors = [</span><br><span class="line">  &#123; name=<span class="string">&quot;huafengchun&quot;</span>, email=<span class="string">&quot;huafengchun@huawei.com&quot;</span> &#125;,</span><br><span class="line">]</span><br><span class="line">classifiers = [</span><br><span class="line">    <span class="string">&quot;Programming Language :: Python :: 3&quot;</span>,</span><br><span class="line">    <span class="string">&quot;License :: OSI Approved :: MIT License&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Operating System :: OS Independent&quot;</span>,</span><br><span class="line">]</span><br><span class="line">keywords = [<span class="string">&quot;sum&quot;</span>, <span class="string">&quot;avg&quot;</span>]</span><br><span class="line"></span><br><span class="line">[project.urls]</span><br><span class="line"><span class="string">&quot;Homepage&quot;</span> = <span class="string">&quot;w3.huawei.com&quot;</span></span><br><span class="line"></span><br><span class="line">[tool.setuptools]</span><br><span class="line">py-modules = [<span class="string">&quot;_custom_build&quot;</span>]</span><br><span class="line"></span><br><span class="line">[tool.setuptools.cmdclass]</span><br><span class="line">build_py = <span class="string">&quot;_custom_build.build_py&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># _custom_build.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> setuptools <span class="keyword">import</span> Extension</span><br><span class="line"><span class="keyword">from</span> setuptools.command.build_py <span class="keyword">import</span> build_py <span class="keyword">as</span> _build_py</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">build_py</span>(<span class="title class_ inherited__">_build_py</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        self.run_command(<span class="string">&quot;build_ext&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().run()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">initialize_options</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().initialize_options()</span><br><span class="line">        <span class="keyword">if</span> self.distribution.ext_modules == <span class="literal">None</span>:</span><br><span class="line">            self.distribution.ext_modules = []</span><br><span class="line"></span><br><span class="line">        self.distribution.ext_modules.append(</span><br><span class="line"></span><br><span class="line">            Extension(</span><br><span class="line">                <span class="string">&quot;libsum&quot;</span>,</span><br><span class="line">                sources=[<span class="string">&quot;libsum.c&quot;</span>],</span><br><span class="line">                extra_compile_args=[<span class="string">&#x27;-g&#x27;</span>, <span class="string">&#x27;-I/home/hua/anaconda3/include/python3.10&#x27;</span>, <span class="string">&#x27;-I/home/hua/anaconda3/lib/python3.10/site-packages/pybind11/include&#x27;</span>],</span><br><span class="line">            )</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">python -m build</span><br><span class="line"></span><br><span class="line">base) hua@hfc-ascend:~/code/share$ ll</span><br><span class="line">total 2488</span><br><span class="line">drwxrwxr-x 7 hua hua    4096 Jun  5 09:20 ./</span><br><span class="line">drwxrwxr-x 5 hua hua    4096 May 30 11:08 ../</span><br><span class="line">drwxrwxr-x 4 hua hua    4096 Jun  5 09:17 build/</span><br><span class="line">-rw-rw-r-- 1 hua hua     716 Jun  5 09:16 _custom_build.py</span><br><span class="line">drwxrwxr-x 2 hua hua    4096 Jun  5 09:16 dist/</span><br><span class="line">-rw-rw-r-- 1 hua hua    9015 May 29 19:14 libsum.cc</span><br><span class="line">-rwxrwxr-x 1 hua hua 2485776 Jun  5 09:17 libsum.cpython-310-x86_64-linux-gnu.so*</span><br><span class="line">drwxrwxr-x 2 hua hua    4096 Jun  5 09:16 libsum.egg-info/</span><br><span class="line">-rw-rw-r-- 1 hua hua    1715 May 29 19:33 libsum_pybind11.cc</span><br><span class="line">drwxrwxr-x 2 hua hua    4096 Jun  5 09:16 __pycache__/</span><br><span class="line">-rw-rw-r-- 1 hua hua     660 Jun  5 09:16 pyproject.toml</span><br><span class="line">-rw-rw-r-- 1 hua hua     535 May 29 19:17 py_sum.py</span><br><span class="line">-rw-rw-r-- 1 hua hua     477 May 29 19:16 setup.py</span><br><span class="line">drwxrwxr-x 2 hua hua    4096 May 30 11:32 .vscode/</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/06/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="hipudding">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="hipudding's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | hipudding's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/06/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-06-06 09:09:56" itemprop="dateCreated datePublished" datetime="2023-06-06T09:09:56+08:00">2023-06-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very
first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a
target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a
target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a
target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a
target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a
target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">hipudding</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/hipudding" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
